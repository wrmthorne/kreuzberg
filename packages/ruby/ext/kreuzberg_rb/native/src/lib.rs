//! Kreuzberg Ruby Bindings (Magnus)
//!
//! High-performance document intelligence framework bindings for Ruby.
//! Provides extraction, OCR, chunking, and language detection for 30+ file formats.

use kreuzberg::{
    ChunkingConfig, ExtractionConfig, ExtractionResult as RustExtractionResult, ImageExtractionConfig,
    ImagePreprocessingConfig, KreuzbergError, LanguageDetectionConfig, OcrConfig, PdfConfig, PostProcessorConfig,
    TokenReductionConfig,
};
use magnus::exception::ExceptionClass;
use magnus::r_hash::ForEach;
use magnus::value::ReprValue;
use magnus::{Error, IntoValue, RArray, RHash, Ruby, Symbol, TryConvert, Value, function, scan_args::scan_args};
use std::fs;
use std::path::{Path, PathBuf};

/// Convert Kreuzberg errors to Ruby exceptions
fn kreuzberg_error(err: KreuzbergError) -> Error {
    let ruby = Ruby::get().expect("Ruby not initialized");

    let fetch_error_class = |name: &str| -> Option<ExceptionClass> {
        ruby.eval::<ExceptionClass>(&format!("Kreuzberg::Errors::{}", name))
            .ok()
    };

    match err {
        KreuzbergError::Validation { message, .. } => {
            if let Some(class) = fetch_error_class("ValidationError") {
                Error::new(class, message)
            } else {
                Error::new(ruby.exception_arg_error(), message)
            }
        }
        KreuzbergError::Parsing { message, .. } => {
            if let Some(class) = fetch_error_class("ParsingError") {
                Error::new(class, message)
            } else {
                Error::new(ruby.exception_runtime_error(), format!("ParsingError: {}", message))
            }
        }
        KreuzbergError::Ocr { message, .. } => {
            if let Some(class) = fetch_error_class("OCRError") {
                Error::new(class, message)
            } else {
                Error::new(ruby.exception_runtime_error(), format!("OCRError: {}", message))
            }
        }
        KreuzbergError::MissingDependency(message) => {
            if let Some(class) = fetch_error_class("MissingDependencyError") {
                Error::new(class, message)
            } else {
                Error::new(
                    ruby.exception_runtime_error(),
                    format!("MissingDependencyError: {}", message),
                )
            }
        }
        KreuzbergError::Plugin { message, plugin_name } => {
            if let Some(class) = fetch_error_class("PluginError") {
                Error::new(class, format!("{}: {}", plugin_name, message))
            } else {
                Error::new(
                    ruby.exception_runtime_error(),
                    format!("Plugin error in '{}': {}", plugin_name, message),
                )
            }
        }
        KreuzbergError::Io(err) => {
            if let Some(class) = fetch_error_class("IOError") {
                Error::new(class, err.to_string())
            } else {
                Error::new(ruby.exception_runtime_error(), format!("IO error: {}", err))
            }
        }
        other => Error::new(ruby.exception_runtime_error(), other.to_string()),
    }
}

fn runtime_error(message: impl Into<String>) -> Error {
    let ruby = Ruby::get().expect("Ruby not initialized");
    Error::new(ruby.exception_runtime_error(), message.into())
}

/// Convert Ruby Symbol or String to Rust String
fn symbol_to_string(value: Value) -> Result<String, Error> {
    if let Some(symbol) = Symbol::from_value(value) {
        Ok(symbol.name()?.to_string())
    } else {
        String::try_convert(value)
    }
}

/// Get keyword argument from hash (supports both symbol and string keys)
fn get_kw(ruby: &Ruby, hash: RHash, name: &str) -> Option<Value> {
    hash.get(name).or_else(|| {
        let sym = ruby.intern(name);
        hash.get(sym)
    })
}

fn set_hash_entry(ruby: &Ruby, hash: &RHash, key: &str, value: Value) -> Result<(), Error> {
    hash.aset(ruby.intern(key), value)?;
    let string_key = ruby.str_new(key).into_value_with(ruby);
    hash.aset(string_key, value)?;
    Ok(())
}

fn ocr_config_to_ruby_hash(ruby: &Ruby, config: &kreuzberg::OcrConfig) -> Result<RHash, Error> {
    let value =
        serde_json::to_value(config).map_err(|e| runtime_error(format!("Failed to serialize OCR config: {}", e)))?;
    let ruby_value = json_value_to_ruby(ruby, &value)?;
    RHash::try_convert(ruby_value).map_err(|_| runtime_error("OCR config must return a Hash"))
}

fn cache_root_dir() -> Result<PathBuf, Error> {
    std::env::current_dir()
        .map(|dir| dir.join(".kreuzberg"))
        .map_err(|e| runtime_error(format!("Failed to get current directory: {}", e)))
}

fn cache_directories(root: &Path) -> Result<Vec<PathBuf>, Error> {
    if !root.exists() {
        return Ok(vec![]);
    }

    let mut dirs = vec![root.to_path_buf()];
    let entries = fs::read_dir(root).map_err(|e| runtime_error(format!("Failed to read cache root: {}", e)))?;

    for entry in entries {
        let entry = entry.map_err(|e| runtime_error(format!("Failed to read cache directory entry: {}", e)))?;
        if entry
            .file_type()
            .map_err(|e| runtime_error(format!("Failed to determine cache entry type: {}", e)))?
            .is_dir()
        {
            dirs.push(entry.path());
        }
    }

    Ok(dirs)
}

fn json_value_to_ruby(ruby: &Ruby, value: &serde_json::Value) -> Result<Value, Error> {
    Ok(match value {
        serde_json::Value::Null => ruby.qnil().as_value(),
        serde_json::Value::Bool(b) => {
            if *b {
                ruby.qtrue().as_value()
            } else {
                ruby.qfalse().as_value()
            }
        }
        serde_json::Value::Number(num) => {
            if let Some(i) = num.as_i64() {
                ruby.integer_from_i64(i).into_value_with(ruby)
            } else if let Some(u) = num.as_u64() {
                ruby.integer_from_u64(u).into_value_with(ruby)
            } else if let Some(f) = num.as_f64() {
                ruby.float_from_f64(f).into_value_with(ruby)
            } else {
                ruby.qnil().as_value()
            }
        }
        serde_json::Value::String(s) => ruby.str_new(s).into_value_with(ruby),
        serde_json::Value::Array(items) => {
            let ary = ruby.ary_new();
            for item in items {
                ary.push(json_value_to_ruby(ruby, item)?)?;
            }
            ary.into_value_with(ruby)
        }
        serde_json::Value::Object(map) => {
            let hash = ruby.hash_new();
            for (key, val) in map {
                let key_value = ruby.str_new(key).into_value_with(ruby);
                let val_value = json_value_to_ruby(ruby, val)?;
                hash.aset(key_value, val_value)?;
            }
            hash.into_value_with(ruby)
        }
    })
}

fn ruby_key_to_string(value: Value) -> Result<String, Error> {
    if let Ok(sym) = Symbol::try_convert(value) {
        Ok(sym.name()?.to_string())
    } else {
        String::try_convert(value)
    }
}

fn ruby_value_to_json(value: Value) -> Result<serde_json::Value, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");

    if value.is_nil() {
        return Ok(serde_json::Value::Null);
    }

    if value.equal(ruby.qtrue())? {
        return Ok(serde_json::Value::Bool(true));
    }

    if value.equal(ruby.qfalse())? {
        return Ok(serde_json::Value::Bool(false));
    }

    if let Ok(integer) = i64::try_convert(value) {
        return Ok(serde_json::Value::Number(integer.into()));
    }

    if let Ok(unsigned) = u64::try_convert(value) {
        return Ok(serde_json::Value::Number(serde_json::Number::from(unsigned)));
    }

    if let Ok(float) = f64::try_convert(value) {
        if let Some(num) = serde_json::Number::from_f64(float) {
            return Ok(serde_json::Value::Number(num));
        }
    }

    if let Ok(sym) = Symbol::try_convert(value) {
        return Ok(serde_json::Value::String(sym.name()?.to_string()));
    }

    if let Ok(string) = String::try_convert(value) {
        return Ok(serde_json::Value::String(string));
    }

    if let Ok(array) = RArray::try_convert(value) {
        let mut values = Vec::with_capacity(array.len());
        for item in array.into_iter() {
            values.push(ruby_value_to_json(item)?);
        }
        return Ok(serde_json::Value::Array(values));
    }

    if let Ok(hash) = RHash::try_convert(value) {
        let mut map = serde_json::Map::new();
        hash.foreach(|key: Value, val: Value| {
            let key_string = ruby_key_to_string(key)?;
            let json_value = ruby_value_to_json(val)?;
            map.insert(key_string, json_value);
            Ok(ForEach::Continue)
        })?;

        return Ok(serde_json::Value::Object(map));
    }

    Err(runtime_error("Unsupported Ruby value for JSON conversion"))
}

/// Parse OcrConfig from Ruby Hash
fn parse_ocr_config(ruby: &Ruby, hash: RHash) -> Result<OcrConfig, Error> {
    let backend = if let Some(val) = get_kw(ruby, hash, "backend") {
        symbol_to_string(val)?
    } else {
        "tesseract".to_string()
    };

    let language = if let Some(val) = get_kw(ruby, hash, "language") {
        symbol_to_string(val)?
    } else {
        "eng".to_string()
    };

    let config = OcrConfig {
        backend,
        language,
        tesseract_config: None,
    };

    Ok(config)
}

/// Parse ChunkingConfig from Ruby Hash
fn parse_chunking_config(ruby: &Ruby, hash: RHash) -> Result<ChunkingConfig, Error> {
    let max_chars = if let Some(val) = get_kw(ruby, hash, "max_chars") {
        usize::try_convert(val)?
    } else {
        1000
    };

    let max_overlap = if let Some(val) = get_kw(ruby, hash, "max_overlap") {
        usize::try_convert(val)?
    } else {
        200
    };

    let preset = if let Some(val) = get_kw(ruby, hash, "preset")
        && !val.is_nil()
    {
        Some(symbol_to_string(val)?)
    } else {
        None
    };

    let config = ChunkingConfig {
        max_chars,
        max_overlap,
        embedding: None, // TODO: Support embedding config from Ruby
        preset,
    };

    Ok(config)
}

/// Parse LanguageDetectionConfig from Ruby Hash
fn parse_language_detection_config(ruby: &Ruby, hash: RHash) -> Result<LanguageDetectionConfig, Error> {
    let enabled = if let Some(val) = get_kw(ruby, hash, "enabled") {
        bool::try_convert(val)?
    } else {
        true
    };

    let min_confidence = if let Some(val) = get_kw(ruby, hash, "min_confidence") {
        f64::try_convert(val)?
    } else {
        0.8
    };

    let detect_multiple = if let Some(val) = get_kw(ruby, hash, "detect_multiple") {
        bool::try_convert(val)?
    } else {
        false
    };

    let config = LanguageDetectionConfig {
        enabled,
        min_confidence,
        detect_multiple,
    };

    Ok(config)
}

/// Parse PdfConfig from Ruby Hash
fn parse_pdf_config(ruby: &Ruby, hash: RHash) -> Result<PdfConfig, Error> {
    let extract_images = if let Some(val) = get_kw(ruby, hash, "extract_images") {
        bool::try_convert(val)?
    } else {
        false
    };

    let passwords = if let Some(val) = get_kw(ruby, hash, "passwords") {
        if !val.is_nil() {
            let arr = RArray::try_convert(val)?;
            Some(arr.to_vec::<String>()?)
        } else {
            None
        }
    } else {
        None
    };

    let extract_metadata = if let Some(val) = get_kw(ruby, hash, "extract_metadata") {
        bool::try_convert(val)?
    } else {
        true
    };

    let config = PdfConfig {
        extract_images,
        passwords,
        extract_metadata,
    };

    Ok(config)
}

/// Parse ImageExtractionConfig from Ruby Hash
fn parse_image_extraction_config(ruby: &Ruby, hash: RHash) -> Result<ImageExtractionConfig, Error> {
    let extract_images = if let Some(val) = get_kw(ruby, hash, "extract_images") {
        bool::try_convert(val)?
    } else {
        true
    };

    let target_dpi = if let Some(val) = get_kw(ruby, hash, "target_dpi") {
        i32::try_convert(val)?
    } else {
        300
    };

    let max_image_dimension = if let Some(val) = get_kw(ruby, hash, "max_image_dimension") {
        i32::try_convert(val)?
    } else {
        4096
    };

    let auto_adjust_dpi = if let Some(val) = get_kw(ruby, hash, "auto_adjust_dpi") {
        bool::try_convert(val)?
    } else {
        true
    };

    let min_dpi = if let Some(val) = get_kw(ruby, hash, "min_dpi") {
        i32::try_convert(val)?
    } else {
        72
    };

    let max_dpi = if let Some(val) = get_kw(ruby, hash, "max_dpi") {
        i32::try_convert(val)?
    } else {
        600
    };

    let config = ImageExtractionConfig {
        extract_images,
        target_dpi,
        max_image_dimension,
        auto_adjust_dpi,
        min_dpi,
        max_dpi,
    };

    Ok(config)
}

/// Parse ImagePreprocessingConfig from Ruby Hash
///
/// Note: Currently not used in ExtractionConfig but provided for completeness.
/// ImagePreprocessingConfig is typically used in OCR operations.
#[allow(dead_code)]
fn parse_image_preprocessing_config(ruby: &Ruby, hash: RHash) -> Result<ImagePreprocessingConfig, Error> {
    let target_dpi = if let Some(val) = get_kw(ruby, hash, "target_dpi") {
        i32::try_convert(val)?
    } else {
        300
    };

    let auto_rotate = if let Some(val) = get_kw(ruby, hash, "auto_rotate") {
        bool::try_convert(val)?
    } else {
        true
    };

    let deskew = if let Some(val) = get_kw(ruby, hash, "deskew") {
        bool::try_convert(val)?
    } else {
        true
    };

    let denoise = if let Some(val) = get_kw(ruby, hash, "denoise") {
        bool::try_convert(val)?
    } else {
        false
    };

    let contrast_enhance = if let Some(val) = get_kw(ruby, hash, "contrast_enhance") {
        bool::try_convert(val)?
    } else {
        false
    };

    let binarization_method = if let Some(val) = get_kw(ruby, hash, "binarization_method") {
        symbol_to_string(val)?
    } else {
        "otsu".to_string()
    };

    let invert_colors = if let Some(val) = get_kw(ruby, hash, "invert_colors") {
        bool::try_convert(val)?
    } else {
        false
    };

    let config = ImagePreprocessingConfig {
        target_dpi,
        auto_rotate,
        deskew,
        denoise,
        contrast_enhance,
        binarization_method,
        invert_colors,
    };

    Ok(config)
}

/// Parse PostProcessorConfig from Ruby Hash
fn parse_postprocessor_config(ruby: &Ruby, hash: RHash) -> Result<PostProcessorConfig, Error> {
    let enabled = if let Some(val) = get_kw(ruby, hash, "enabled") {
        bool::try_convert(val)?
    } else {
        true
    };

    let enabled_processors = if let Some(val) = get_kw(ruby, hash, "enabled_processors")
        && !val.is_nil()
    {
        let arr = RArray::try_convert(val)?;
        Some(arr.to_vec::<String>()?)
    } else {
        None
    };

    let disabled_processors = if let Some(val) = get_kw(ruby, hash, "disabled_processors")
        && !val.is_nil()
    {
        let arr = RArray::try_convert(val)?;
        Some(arr.to_vec::<String>()?)
    } else {
        None
    };

    let config = PostProcessorConfig {
        enabled,
        enabled_processors,
        disabled_processors,
    };

    Ok(config)
}

/// Parse TokenReductionConfig from Ruby Hash
fn parse_token_reduction_config(ruby: &Ruby, hash: RHash) -> Result<TokenReductionConfig, Error> {
    let mode = if let Some(val) = get_kw(ruby, hash, "mode") {
        symbol_to_string(val)?
    } else {
        "off".to_string()
    };

    let preserve_important_words = if let Some(val) = get_kw(ruby, hash, "preserve_important_words") {
        bool::try_convert(val)?
    } else {
        true
    };

    let config = TokenReductionConfig {
        mode,
        preserve_important_words,
    };

    Ok(config)
}

/// Parse ExtractionConfig from Ruby Hash
fn parse_extraction_config(ruby: &Ruby, opts: Option<RHash>) -> Result<ExtractionConfig, Error> {
    let mut config = ExtractionConfig::default();

    if let Some(hash) = opts {
        if let Some(val) = get_kw(ruby, hash, "use_cache") {
            config.use_cache = bool::try_convert(val)?;
        }

        if let Some(val) = get_kw(ruby, hash, "enable_quality_processing") {
            config.enable_quality_processing = bool::try_convert(val)?;
        }

        if let Some(val) = get_kw(ruby, hash, "force_ocr") {
            config.force_ocr = bool::try_convert(val)?;
        }

        if let Some(val) = get_kw(ruby, hash, "ocr")
            && !val.is_nil()
        {
            let ocr_hash = RHash::try_convert(val)?;
            config.ocr = Some(parse_ocr_config(ruby, ocr_hash)?);
        }

        if let Some(val) = get_kw(ruby, hash, "chunking")
            && !val.is_nil()
        {
            let chunking_hash = RHash::try_convert(val)?;
            config.chunking = Some(parse_chunking_config(ruby, chunking_hash)?);
        }

        if let Some(val) = get_kw(ruby, hash, "language_detection")
            && !val.is_nil()
        {
            let lang_hash = RHash::try_convert(val)?;
            config.language_detection = Some(parse_language_detection_config(ruby, lang_hash)?);
        }

        if let Some(val) = get_kw(ruby, hash, "pdf_options")
            && !val.is_nil()
        {
            let pdf_hash = RHash::try_convert(val)?;
            config.pdf_options = Some(parse_pdf_config(ruby, pdf_hash)?);
        }

        if let Some(val) = get_kw(ruby, hash, "images")
            && !val.is_nil()
        {
            let images_hash = RHash::try_convert(val)?;
            config.images = Some(parse_image_extraction_config(ruby, images_hash)?);
        }

        if let Some(val) = get_kw(ruby, hash, "postprocessor")
            && !val.is_nil()
        {
            let postprocessor_hash = RHash::try_convert(val)?;
            config.postprocessor = Some(parse_postprocessor_config(ruby, postprocessor_hash)?);
        }

        if let Some(val) = get_kw(ruby, hash, "token_reduction")
            && !val.is_nil()
        {
            let token_reduction_hash = RHash::try_convert(val)?;
            config.token_reduction = Some(parse_token_reduction_config(ruby, token_reduction_hash)?);
        }
    }

    Ok(config)
}

/// Convert Rust ExtractionResult to Ruby Hash
fn extraction_result_to_ruby(ruby: &Ruby, result: RustExtractionResult) -> Result<RHash, Error> {
    let hash = ruby.hash_new();

    let content_value = ruby.str_new(result.content.as_str()).into_value_with(ruby);
    set_hash_entry(ruby, &hash, "content", content_value)?;

    let mime_value = ruby.str_new(result.mime_type.as_str()).into_value_with(ruby);
    set_hash_entry(ruby, &hash, "mime_type", mime_value)?;

    let metadata_json = serde_json::to_string(&result.metadata)
        .map_err(|e| runtime_error(format!("Failed to serialize metadata: {}", e)))?;
    let metadata_json_value = ruby.str_new(&metadata_json).into_value_with(ruby);
    set_hash_entry(ruby, &hash, "metadata_json", metadata_json_value)?;
    let metadata_value = serde_json::to_value(&result.metadata)
        .map_err(|e| runtime_error(format!("Failed to serialize metadata: {}", e)))?;
    let metadata_hash = json_value_to_ruby(ruby, &metadata_value)?;
    set_hash_entry(ruby, &hash, "metadata", metadata_hash)?;

    let tables_array = ruby.ary_new();
    for table in result.tables {
        let table_hash = ruby.hash_new();

        let cells_array = ruby.ary_new();
        for row in table.cells {
            let row_array = ruby.ary_from_vec(row);
            cells_array.push(row_array)?;
        }
        table_hash.aset(ruby.intern("cells"), cells_array)?;

        table_hash.aset(ruby.intern("markdown"), table.markdown)?;

        table_hash.aset(ruby.intern("page_number"), table.page_number)?;

        tables_array.push(table_hash)?;
    }
    let tables_value = tables_array.into_value_with(ruby);
    set_hash_entry(ruby, &hash, "tables", tables_value)?;

    if let Some(langs) = result.detected_languages {
        let langs_array = ruby.ary_from_vec(langs);
        let langs_value = langs_array.into_value_with(ruby);
        set_hash_entry(ruby, &hash, "detected_languages", langs_value)?;
    } else {
        set_hash_entry(ruby, &hash, "detected_languages", ruby.qnil().as_value())?;
    }

    if let Some(chunks) = result.chunks {
        let chunks_array = ruby.ary_new();
        for chunk in chunks {
            let chunk_hash = ruby.hash_new();
            chunk_hash.aset(ruby.intern("content"), chunk.content)?;
            chunk_hash.aset(ruby.intern("char_start"), chunk.metadata.char_start)?;
            chunk_hash.aset(ruby.intern("char_end"), chunk.metadata.char_end)?;
            if let Some(token_count) = chunk.metadata.token_count {
                chunk_hash.aset(ruby.intern("token_count"), token_count)?;
            }
            chunks_array.push(chunk_hash)?;
        }
        let chunks_value = chunks_array.into_value_with(ruby);
        set_hash_entry(ruby, &hash, "chunks", chunks_value)?;
    } else {
        set_hash_entry(ruby, &hash, "chunks", ruby.qnil().as_value())?;
    }

    Ok(hash)
}

/// Extract content from a file (synchronous).
///
/// @param path [String] Path to the file
/// @param mime_type [String, nil] Optional MIME type hint
/// @param options [Hash] Extraction configuration
/// @return [Hash] Extraction result with :content, :mime_type, :metadata, :tables, etc.
///
/// @example Basic usage
///   result = Kreuzberg.extract_file_sync("document.pdf")
///   puts result[:content]
///
/// @example With OCR
///   result = Kreuzberg.extract_file_sync("scanned.pdf", nil, force_ocr: true)
///
fn extract_file_sync(args: &[Value]) -> Result<RHash, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(String,), (Option<String>,), (), (), RHash, ()>(args)?;
    let (path,) = args.required;
    let (mime_type,) = args.optional;
    let opts = Some(args.keywords);

    let config = parse_extraction_config(&ruby, opts)?;

    let result = kreuzberg::extract_file_sync(&path, mime_type.as_deref(), &config).map_err(kreuzberg_error)?;

    extraction_result_to_ruby(&ruby, result)
}

/// Extract content from bytes (synchronous).
///
/// @param data [String] Binary data to extract
/// @param mime_type [String] MIME type of the data
/// @param options [Hash] Extraction configuration
/// @return [Hash] Extraction result
///
/// @example
///   data = File.binread("document.pdf")
///   result = Kreuzberg.extract_bytes_sync(data, "application/pdf")
///
fn extract_bytes_sync(args: &[Value]) -> Result<RHash, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(String, String), (), (), (), RHash, ()>(args)?;
    let (data, mime_type) = args.required;
    let opts = Some(args.keywords);

    let config = parse_extraction_config(&ruby, opts)?;

    let result = kreuzberg::extract_bytes_sync(data.as_bytes(), &mime_type, &config).map_err(kreuzberg_error)?;

    extraction_result_to_ruby(&ruby, result)
}

/// Batch extract content from multiple files (synchronous).
///
/// @param paths [Array<String>] List of file paths
/// @param options [Hash] Extraction configuration
/// @return [Array<Hash>] Array of extraction results
///
/// @example
///   paths = ["doc1.pdf", "doc2.docx", "doc3.xlsx"]
///   results = Kreuzberg.batch_extract_files_sync(paths)
///   results.each { |r| puts r[:content] }
///
fn batch_extract_files_sync(args: &[Value]) -> Result<RArray, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(RArray,), (), (), (), RHash, ()>(args)?;
    let (paths_array,) = args.required;
    let opts = Some(args.keywords);

    let config = parse_extraction_config(&ruby, opts)?;

    let paths: Vec<String> = paths_array.to_vec::<String>()?;

    let results = kreuzberg::batch_extract_file_sync(paths, &config).map_err(kreuzberg_error)?;

    let results_array = ruby.ary_new();
    for result in results {
        results_array.push(extraction_result_to_ruby(&ruby, result)?)?;
    }

    Ok(results_array)
}

/// Extract content from a file (asynchronous).
///
/// Note: Ruby doesn't have native async/await, so this uses a blocking Tokio runtime.
/// For true async behavior, use the synchronous version in a background thread.
///
/// @param path [String] Path to the file
/// @param mime_type [String, nil] Optional MIME type hint
/// @param options [Hash] Extraction configuration
/// @return [Hash] Extraction result
///
fn extract_file(args: &[Value]) -> Result<RHash, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(String,), (Option<String>,), (), (), RHash, ()>(args)?;
    let (path,) = args.required;
    let (mime_type,) = args.optional;
    let opts = Some(args.keywords);

    let config = parse_extraction_config(&ruby, opts)?;

    let runtime =
        tokio::runtime::Runtime::new().map_err(|e| runtime_error(format!("Failed to create Tokio runtime: {}", e)))?;

    let result = runtime
        .block_on(async { kreuzberg::extract_file(&path, mime_type.as_deref(), &config).await })
        .map_err(kreuzberg_error)?;

    extraction_result_to_ruby(&ruby, result)
}

/// Extract content from bytes (asynchronous).
///
/// @param data [String] Binary data
/// @param mime_type [String] MIME type
/// @param options [Hash] Extraction configuration
/// @return [Hash] Extraction result
///
fn extract_bytes(args: &[Value]) -> Result<RHash, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(String, String), (), (), (), RHash, ()>(args)?;
    let (data, mime_type) = args.required;
    let opts = Some(args.keywords);

    let config = parse_extraction_config(&ruby, opts)?;

    let runtime =
        tokio::runtime::Runtime::new().map_err(|e| runtime_error(format!("Failed to create Tokio runtime: {}", e)))?;

    let result = runtime
        .block_on(async { kreuzberg::extract_bytes(data.as_bytes(), &mime_type, &config).await })
        .map_err(kreuzberg_error)?;

    extraction_result_to_ruby(&ruby, result)
}

/// Batch extract content from multiple files (asynchronous).
///
/// @param paths [Array<String>] List of file paths
/// @param options [Hash] Extraction configuration
/// @return [Array<Hash>] Array of extraction results
///
fn batch_extract_files(args: &[Value]) -> Result<RArray, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(RArray,), (), (), (), RHash, ()>(args)?;
    let (paths_array,) = args.required;
    let opts = Some(args.keywords);

    let config = parse_extraction_config(&ruby, opts)?;

    let paths: Vec<String> = paths_array.to_vec::<String>()?;

    let runtime =
        tokio::runtime::Runtime::new().map_err(|e| runtime_error(format!("Failed to create Tokio runtime: {}", e)))?;

    let results = runtime
        .block_on(async { kreuzberg::batch_extract_file(paths, &config).await })
        .map_err(kreuzberg_error)?;

    let results_array = ruby.ary_new();
    for result in results {
        results_array.push(extraction_result_to_ruby(&ruby, result)?)?;
    }

    Ok(results_array)
}

/// Batch extract content from multiple byte arrays (synchronous).
///
/// @param bytes_array [Array<String>] List of binary data strings
/// @param mime_types [Array<String>] List of MIME types corresponding to each byte array
/// @param options [Hash] Extraction configuration
/// @return [Array<Hash>] Array of extraction results
///
/// @example
///   data1 = File.binread("document.pdf")
///   data2 = File.binread("invoice.docx")
///   results = Kreuzberg.batch_extract_bytes_sync([data1, data2], ["application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"])
///
fn batch_extract_bytes_sync(args: &[Value]) -> Result<RArray, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(RArray, RArray), (), (), (), RHash, ()>(args)?;
    let (bytes_array, mime_types_array) = args.required;
    let opts = Some(args.keywords);

    let config = parse_extraction_config(&ruby, opts)?;

    let bytes_vec: Vec<String> = bytes_array.to_vec::<String>()?;
    let mime_types: Vec<String> = mime_types_array.to_vec::<String>()?;

    if bytes_vec.len() != mime_types.len() {
        return Err(runtime_error(format!(
            "bytes_array and mime_types must have the same length: {} vs {}",
            bytes_vec.len(),
            mime_types.len()
        )));
    }

    let contents: Vec<(&[u8], &str)> = bytes_vec
        .iter()
        .zip(mime_types.iter())
        .map(|(bytes, mime)| (bytes.as_bytes(), mime.as_str()))
        .collect();

    let results = kreuzberg::batch_extract_bytes_sync(contents, &config).map_err(kreuzberg_error)?;

    let results_array = ruby.ary_new();
    for result in results {
        results_array.push(extraction_result_to_ruby(&ruby, result)?)?;
    }

    Ok(results_array)
}

/// Batch extract content from multiple byte arrays (asynchronous).
///
/// @param bytes_array [Array<String>] List of binary data strings
/// @param mime_types [Array<String>] List of MIME types corresponding to each byte array
/// @param options [Hash] Extraction configuration
/// @return [Array<Hash>] Array of extraction results
///
fn batch_extract_bytes(args: &[Value]) -> Result<RArray, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(RArray, RArray), (), (), (), RHash, ()>(args)?;
    let (bytes_array, mime_types_array) = args.required;
    let opts = Some(args.keywords);

    let config = parse_extraction_config(&ruby, opts)?;

    let bytes_vec: Vec<String> = bytes_array.to_vec::<String>()?;
    let mime_types: Vec<String> = mime_types_array.to_vec::<String>()?;

    if bytes_vec.len() != mime_types.len() {
        return Err(runtime_error(format!(
            "bytes_array and mime_types must have the same length: {} vs {}",
            bytes_vec.len(),
            mime_types.len()
        )));
    }

    let contents: Vec<(&[u8], &str)> = bytes_vec
        .iter()
        .zip(mime_types.iter())
        .map(|(bytes, mime)| (bytes.as_bytes(), mime.as_str()))
        .collect();

    let runtime =
        tokio::runtime::Runtime::new().map_err(|e| runtime_error(format!("Failed to create Tokio runtime: {}", e)))?;

    let results = runtime
        .block_on(async { kreuzberg::batch_extract_bytes(contents, &config).await })
        .map_err(kreuzberg_error)?;

    let results_array = ruby.ary_new();
    for result in results {
        results_array.push(extraction_result_to_ruby(&ruby, result)?)?;
    }

    Ok(results_array)
}

/// Clear all cache entries.
///
/// @return [void]
///
/// @example
///   Kreuzberg.clear_cache
///
fn ruby_clear_cache() -> Result<(), Error> {
    let cache_root = cache_root_dir()?;
    if !cache_root.exists() {
        return Ok(());
    }

    for dir in cache_directories(&cache_root)? {
        let Some(dir_str) = dir.to_str() else {
            return Err(runtime_error("Cache directory path contains non-UTF8 characters"));
        };

        // OSError/RuntimeError must bubble up - system errors need user reports ~keep
        kreuzberg::cache::clear_cache_directory(dir_str).map_err(kreuzberg_error)?;
    }

    Ok(())
}

/// Get cache statistics.
///
/// @return [Hash] Cache statistics with :total_entries and :total_size_bytes
///
/// @example
///   stats = Kreuzberg.cache_stats
///   puts "Cache entries: #{stats[:total_entries]}"
///   puts "Cache size: #{stats[:total_size_bytes]} bytes"
///
fn ruby_cache_stats() -> Result<RHash, Error> {
    let ruby = Ruby::get().expect("Ruby not initialized");

    let hash = ruby.hash_new();
    let cache_root = cache_root_dir()?;

    if !cache_root.exists() {
        hash.aset(ruby.intern("total_entries"), 0)?;
        hash.aset(ruby.intern("total_size_bytes"), 0)?;
        return Ok(hash);
    }

    let mut total_entries: usize = 0;
    let mut total_bytes: f64 = 0.0;

    for dir in cache_directories(&cache_root)? {
        let Some(dir_str) = dir.to_str() else {
            return Err(runtime_error("Cache directory path contains non-UTF8 characters"));
        };

        // OSError/RuntimeError must bubble up - system errors need user reports ~keep
        let stats = kreuzberg::cache::get_cache_metadata(dir_str).map_err(kreuzberg_error)?;
        total_entries += stats.total_files;
        total_bytes += stats.total_size_mb * 1024.0 * 1024.0;
    }

    set_hash_entry(
        &ruby,
        &hash,
        "total_entries",
        ruby.integer_from_u64(total_entries as u64).into_value_with(&ruby),
    )?;
    set_hash_entry(
        &ruby,
        &hash,
        "total_size_bytes",
        ruby.integer_from_u64(total_bytes.round() as u64).into_value_with(&ruby),
    )?;

    Ok(hash)
}

/// Register a post-processor plugin.
///
/// @param name [String] Unique identifier for the post-processor
/// @param processor [Proc] Ruby Proc/lambda that processes extraction results
/// @param priority [Integer] Execution priority (default: 50, higher = runs first)
/// @return [nil]
///
/// # Example
/// ```text
/// Kreuzberg.register_post_processor("uppercase", ->(result) {
///   result[:content] = result[:content].upcase
///   result
/// }, 100)
/// ```
fn register_post_processor(args: &[Value]) -> Result<(), Error> {
    let _ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(String, Value), (Option<i32>,), (), (), (), ()>(args)?;
    let (name, processor) = args.required;
    let (priority,) = args.optional;
    let priority = priority.unwrap_or(50);

    if !processor.respond_to("call", true)? {
        return Err(runtime_error("Post-processor must be a Proc or respond to 'call'"));
    }

    use async_trait::async_trait;
    use kreuzberg::plugins::{Plugin, PostProcessor, ProcessingStage};
    use std::sync::Arc;

    struct RubyPostProcessor {
        name: String,
        processor: magnus::Value,
    }

    unsafe impl Send for RubyPostProcessor {}
    unsafe impl Sync for RubyPostProcessor {}

    impl Plugin for RubyPostProcessor {
        fn name(&self) -> &str {
            &self.name
        }

        fn version(&self) -> String {
            "1.0.0".to_string()
        }

        fn initialize(&self) -> kreuzberg::Result<()> {
            Ok(())
        }

        fn shutdown(&self) -> kreuzberg::Result<()> {
            Ok(())
        }
    }

    #[async_trait]
    impl PostProcessor for RubyPostProcessor {
        async fn process(
            &self,
            result: &mut kreuzberg::ExtractionResult,
            _config: &kreuzberg::ExtractionConfig,
        ) -> kreuzberg::Result<()> {
            let ruby = Ruby::get().expect("Ruby not initialized");
            let result_hash =
                extraction_result_to_ruby(&ruby, result.clone()).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                    message: format!("Failed to convert result to Ruby: {}", e),
                    plugin_name: self.name.clone(),
                })?;

            let modified = self
                .processor
                .funcall::<_, _, magnus::Value>("call", (result_hash,))
                .map_err(|e| kreuzberg::KreuzbergError::Plugin {
                    message: format!("Ruby post-processor failed: {}", e),
                    plugin_name: self.name.clone(),
                })?;

            let modified_hash =
                magnus::RHash::try_convert(modified).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                    message: format!("Post-processor must return a Hash: {}", e),
                    plugin_name: self.name.clone(),
                })?;

            if let Some(content_val) = get_kw(&ruby, modified_hash, "content") {
                let new_content = String::try_convert(content_val).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                    message: format!("Failed to convert content: {}", e),
                    plugin_name: self.name.clone(),
                })?;
                result.content = new_content;
            }

            if let Some(mime_val) = get_kw(&ruby, modified_hash, "mime_type") {
                let new_mime = String::try_convert(mime_val).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                    message: format!("Failed to convert mime_type: {}", e),
                    plugin_name: self.name.clone(),
                })?;
                result.mime_type = new_mime;
            }

            if let Some(metadata_val) = get_kw(&ruby, modified_hash, "metadata") {
                if metadata_val.is_nil() {
                    result.metadata = kreuzberg::types::Metadata::default();
                } else {
                    let metadata_json =
                        ruby_value_to_json(metadata_val).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                            message: format!("Metadata must be JSON-serializable: {}", e),
                            plugin_name: self.name.clone(),
                        })?;
                    let metadata: kreuzberg::types::Metadata =
                        serde_json::from_value(metadata_json).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                            message: format!("Failed to deserialize metadata: {}", e),
                            plugin_name: self.name.clone(),
                        })?;
                    result.metadata = metadata;
                }
            }

            if let Some(tables_val) = get_kw(&ruby, modified_hash, "tables") {
                let tables_json = ruby_value_to_json(tables_val).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                    message: format!("Tables must be JSON-serializable: {}", e),
                    plugin_name: self.name.clone(),
                })?;
                if tables_json.is_null() {
                    result.tables.clear();
                } else {
                    let tables: Vec<kreuzberg::types::Table> =
                        serde_json::from_value(tables_json).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                            message: format!("Failed to deserialize tables: {}", e),
                            plugin_name: self.name.clone(),
                        })?;
                    result.tables = tables;
                }
            }

            if let Some(languages_val) = get_kw(&ruby, modified_hash, "detected_languages") {
                if languages_val.is_nil() {
                    result.detected_languages = None;
                } else {
                    let langs_json =
                        ruby_value_to_json(languages_val).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                            message: format!("detected_languages must be JSON-serializable: {}", e),
                            plugin_name: self.name.clone(),
                        })?;
                    let languages: Vec<String> =
                        serde_json::from_value(langs_json).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                            message: format!("Failed to deserialize detected_languages: {}", e),
                            plugin_name: self.name.clone(),
                        })?;
                    result.detected_languages = Some(languages);
                }
            }

            if let Some(chunks_val) = get_kw(&ruby, modified_hash, "chunks") {
                if chunks_val.is_nil() {
                    result.chunks = None;
                } else {
                    let chunks_json =
                        ruby_value_to_json(chunks_val).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                            message: format!("Chunks must be JSON-serializable: {}", e),
                            plugin_name: self.name.clone(),
                        })?;
                    let chunks: Vec<kreuzberg::types::Chunk> =
                        serde_json::from_value(chunks_json).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                            message: format!("Failed to deserialize chunks: {}", e),
                            plugin_name: self.name.clone(),
                        })?;
                    result.chunks = Some(chunks);
                }
            }

            Ok(())
        }

        fn processing_stage(&self) -> ProcessingStage {
            ProcessingStage::Late
        }
    }

    let processor_impl = Arc::new(RubyPostProcessor {
        name: name.clone(),
        processor,
    });

    let registry = kreuzberg::get_post_processor_registry();
    registry
        .write()
        .map_err(|e| runtime_error(format!("Failed to acquire registry lock: {}", e)))?
        .register(processor_impl, priority)
        .map_err(kreuzberg_error)?;

    Ok(())
}

/// Register a validator plugin.
///
/// @param name [String] Unique identifier for the validator
/// @param validator [Proc] Ruby Proc/lambda that validates extraction results
/// @param priority [Integer] Execution priority (default: 50, higher = runs first)
/// @return [nil]
///
/// # Example
/// ```text
/// Kreuzberg.register_validator("min_length", ->(result) {
///   raise "Content too short" if result[:content].length < 100
/// }, 100)
/// ```
fn register_validator(args: &[Value]) -> Result<(), Error> {
    let _ruby = Ruby::get().expect("Ruby not initialized");
    let args = scan_args::<(String, Value), (Option<i32>,), (), (), (), ()>(args)?;
    let (name, validator) = args.required;
    let (priority,) = args.optional;
    let priority = priority.unwrap_or(50);

    if !validator.respond_to("call", true)? {
        return Err(runtime_error("Validator must be a Proc or respond to 'call'"));
    }

    use async_trait::async_trait;
    use kreuzberg::plugins::{Plugin, Validator};
    use std::sync::Arc;

    struct RubyValidator {
        name: String,
        validator: magnus::Value,
        priority: i32,
    }

    unsafe impl Send for RubyValidator {}
    unsafe impl Sync for RubyValidator {}

    impl Plugin for RubyValidator {
        fn name(&self) -> &str {
            &self.name
        }

        fn version(&self) -> String {
            "1.0.0".to_string()
        }

        fn initialize(&self) -> kreuzberg::Result<()> {
            Ok(())
        }

        fn shutdown(&self) -> kreuzberg::Result<()> {
            Ok(())
        }
    }

    #[async_trait]
    impl Validator for RubyValidator {
        async fn validate(
            &self,
            result: &kreuzberg::ExtractionResult,
            _config: &kreuzberg::ExtractionConfig,
        ) -> kreuzberg::Result<()> {
            let ruby = Ruby::get().expect("Ruby not initialized");
            let result_hash =
                extraction_result_to_ruby(&ruby, result.clone()).map_err(|e| kreuzberg::KreuzbergError::Plugin {
                    message: format!("Failed to convert result to Ruby: {}", e),
                    plugin_name: self.name.clone(),
                })?;

            self.validator
                .funcall::<_, _, magnus::Value>("call", (result_hash,))
                .map_err(|e| kreuzberg::KreuzbergError::Validation {
                    message: format!("Validation failed: {}", e),
                    source: None,
                })?;

            Ok(())
        }

        fn priority(&self) -> i32 {
            self.priority
        }
    }

    let validator_impl = Arc::new(RubyValidator {
        name: name.clone(),
        validator,
        priority,
    });

    let registry = kreuzberg::get_validator_registry();
    registry
        .write()
        .map_err(|e| runtime_error(format!("Failed to acquire registry lock: {}", e)))?
        .register(validator_impl)
        .map_err(kreuzberg_error)?;

    Ok(())
}

/// Register an OCR backend plugin.
///
/// @param name [String] Unique identifier for the OCR backend
/// @param backend [Object] Ruby object implementing OCR backend interface
/// @return [nil]
///
/// # Example
/// ```text
/// class CustomOcr
///   def process_image(image_bytes, language)
///     # Return extracted text
///     "Extracted text"
///   end
///
///   def supports_language?(lang)
///     %w[eng deu fra].include?(lang)
///   end
/// end
///
/// Kreuzberg.register_ocr_backend("custom", CustomOcr.new)
/// ```
fn register_ocr_backend(name: String, backend: Value) -> Result<(), Error> {
    if !backend.respond_to("name", true)? {
        return Err(runtime_error("OCR backend must respond to 'name'"));
    }
    if !backend.respond_to("process_image", true)? {
        return Err(runtime_error("OCR backend must respond to 'process_image'"));
    }

    use async_trait::async_trait;
    use kreuzberg::plugins::{OcrBackend, OcrBackendType, Plugin};
    use std::sync::Arc;

    struct RubyOcrBackend {
        name: String,
        backend: magnus::Value,
    }

    unsafe impl Send for RubyOcrBackend {}
    unsafe impl Sync for RubyOcrBackend {}

    impl Plugin for RubyOcrBackend {
        fn name(&self) -> &str {
            &self.name
        }

        fn version(&self) -> String {
            "1.0.0".to_string()
        }

        fn initialize(&self) -> kreuzberg::Result<()> {
            Ok(())
        }

        fn shutdown(&self) -> kreuzberg::Result<()> {
            Ok(())
        }
    }

    #[async_trait]
    impl OcrBackend for RubyOcrBackend {
        async fn process_image(
            &self,
            image_bytes: &[u8],
            config: &kreuzberg::OcrConfig,
        ) -> kreuzberg::Result<kreuzberg::ExtractionResult> {
            let ruby = Ruby::get().expect("Ruby not initialized");
            let image_str = ruby.str_from_slice(image_bytes);

            let config_hash = ocr_config_to_ruby_hash(&ruby, config).map_err(|e| kreuzberg::KreuzbergError::Ocr {
                message: format!("Failed to convert OCR config: {}", e),
                source: None,
            })?;

            let response = self
                .backend
                .funcall::<_, _, Value>("process_image", (image_str, config_hash.into_value_with(&ruby)))
                .map_err(|e| kreuzberg::KreuzbergError::Ocr {
                    message: format!("Ruby OCR backend failed: {}", e),
                    source: None,
                })?;

            let text = String::try_convert(response).map_err(|e| kreuzberg::KreuzbergError::Ocr {
                message: format!("OCR backend must return a String: {}", e),
                source: None,
            })?;

            Ok(kreuzberg::ExtractionResult {
                content: text,
                mime_type: "text/plain".to_string(),
                metadata: kreuzberg::types::Metadata::default(),
                tables: vec![],
                detected_languages: None,
                chunks: None,
                images: None,
            })
        }

        fn supports_language(&self, lang: &str) -> bool {
            match self.backend.respond_to("supports_language?", true) {
                Ok(true) => self
                    .backend
                    .funcall::<_, _, bool>("supports_language?", (lang,))
                    .unwrap_or(true),
                _ => true,
            }
        }

        fn backend_type(&self) -> OcrBackendType {
            OcrBackendType::Custom
        }
    }

    let backend_impl = Arc::new(RubyOcrBackend {
        name: name.clone(),
        backend,
    });

    let registry = kreuzberg::get_ocr_backend_registry();
    registry
        .write()
        .map_err(|e| runtime_error(format!("Failed to acquire registry lock: {}", e)))?
        .register(backend_impl)
        .map_err(kreuzberg_error)?;

    Ok(())
}

/// Unregister a post-processor plugin.
///
/// @param name [String] Name of the post-processor to remove
/// @return [nil]
///
fn unregister_post_processor(name: String) -> Result<(), Error> {
    let registry = kreuzberg::get_post_processor_registry();
    registry
        .write()
        .map_err(|e| runtime_error(format!("Failed to acquire registry lock: {}", e)))?
        .remove(&name)
        .map_err(kreuzberg_error)?;
    Ok(())
}

/// Unregister a validator plugin.
///
/// @param name [String] Name of the validator to remove
/// @return [nil]
///
fn unregister_validator(name: String) -> Result<(), Error> {
    let registry = kreuzberg::get_validator_registry();
    registry
        .write()
        .map_err(|e| runtime_error(format!("Failed to acquire registry lock: {}", e)))?
        .remove(&name)
        .map_err(kreuzberg_error)?;
    Ok(())
}

/// Clear all registered post-processors.
///
/// @return [nil]
///
fn clear_post_processors() -> Result<(), Error> {
    let registry = kreuzberg::get_post_processor_registry();
    registry
        .write()
        .map_err(|e| runtime_error(format!("Failed to acquire registry lock: {}", e)))?
        .shutdown_all()
        .map_err(kreuzberg_error)?;
    Ok(())
}

/// Clear all registered validators.
///
/// @return [nil]
///
fn clear_validators() -> Result<(), Error> {
    let registry = kreuzberg::get_validator_registry();
    registry
        .write()
        .map_err(|e| runtime_error(format!("Failed to acquire registry lock: {}", e)))?
        .shutdown_all()
        .map_err(kreuzberg_error)?;
    Ok(())
}

/// Initialize the Kreuzberg Ruby module
#[magnus::init]
fn init(ruby: &Ruby) -> Result<(), Error> {
    let module = ruby.define_module("Kreuzberg")?;

    module.define_module_function("extract_file_sync", function!(extract_file_sync, -1))?;
    module.define_module_function("extract_bytes_sync", function!(extract_bytes_sync, -1))?;
    module.define_module_function("batch_extract_files_sync", function!(batch_extract_files_sync, -1))?;
    module.define_module_function("batch_extract_bytes_sync", function!(batch_extract_bytes_sync, -1))?;

    module.define_module_function("extract_file", function!(extract_file, -1))?;
    module.define_module_function("extract_bytes", function!(extract_bytes, -1))?;
    module.define_module_function("batch_extract_files", function!(batch_extract_files, -1))?;
    module.define_module_function("batch_extract_bytes", function!(batch_extract_bytes, -1))?;

    module.define_module_function("clear_cache", function!(ruby_clear_cache, 0))?;
    module.define_module_function("cache_stats", function!(ruby_cache_stats, 0))?;

    module.define_module_function("register_post_processor", function!(register_post_processor, -1))?;
    module.define_module_function("register_validator", function!(register_validator, -1))?;
    module.define_module_function("register_ocr_backend", function!(register_ocr_backend, 2))?;
    module.define_module_function("unregister_post_processor", function!(unregister_post_processor, 1))?;
    module.define_module_function("unregister_validator", function!(unregister_validator, 1))?;
    module.define_module_function("clear_post_processors", function!(clear_post_processors, 0))?;
    module.define_module_function("clear_validators", function!(clear_validators, 0))?;

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_ruby_clear_cache_clears_directory() {
        use std::fs;
        use std::path::PathBuf;

        let thread_id = std::thread::current().id();
        let cache_dir = PathBuf::from(format!("/tmp/kreuzberg_test_clear_{:?}", thread_id));

        let _ = fs::remove_dir_all(&cache_dir);

        fs::create_dir_all(&cache_dir).expect("Failed to create cache directory");

        let test_file = cache_dir.join("test_cache.msgpack");
        fs::write(&test_file, b"test data").expect("Failed to write test file");

        assert!(test_file.exists(), "Test file should exist before clear");

        let cache_dir_str = cache_dir.to_str().expect("Cache dir must be valid UTF-8");
        let result = kreuzberg::cache::clear_cache_directory(cache_dir_str);

        assert!(result.is_ok(), "Cache clear should succeed");
        let (removed, _) = result.unwrap();
        assert_eq!(removed, 1, "Should remove one file");

        assert!(!test_file.exists(), "Test file should be removed after clear");

        let _ = fs::remove_dir_all(&cache_dir);
    }

    #[test]
    fn test_ruby_cache_stats_returns_correct_structure() {
        use std::fs;
        use std::path::PathBuf;

        let thread_id = std::thread::current().id();
        let cache_dir = PathBuf::from(format!("/tmp/kreuzberg_test_stats_{:?}", thread_id));

        let _ = fs::remove_dir_all(&cache_dir);

        fs::create_dir_all(&cache_dir).expect("Failed to create cache directory");

        let test_file1 = cache_dir.join("test1.msgpack");
        let test_file2 = cache_dir.join("test2.msgpack");
        fs::write(&test_file1, b"test data 1").expect("Failed to write test file 1");
        fs::write(&test_file2, b"test data 2").expect("Failed to write test file 2");

        let cache_dir_str = cache_dir.to_str().expect("Cache dir must be valid UTF-8");
        let stats = kreuzberg::cache::get_cache_metadata(cache_dir_str);

        assert!(stats.is_ok(), "Cache stats should succeed");
        let stats = stats.unwrap();

        assert_eq!(stats.total_files, 2, "Should report 2 files");
        assert!(stats.total_size_mb > 0.0, "Total size should be greater than 0");
        assert!(
            stats.available_space_mb > 0.0,
            "Available space should be greater than 0"
        );

        let _ = fs::remove_dir_all(&cache_dir);
    }

    #[test]
    fn test_ruby_cache_stats_converts_mb_to_bytes() {
        let size_mb = 1.5;
        let size_bytes = (size_mb * 1024.0 * 1024.0) as u64;
        assert_eq!(size_bytes, 1_572_864, "Should convert MB to bytes correctly");
    }

    #[test]
    fn test_ruby_clear_cache_handles_empty_directory() {
        use std::fs;
        use std::path::PathBuf;

        let thread_id = std::thread::current().id();
        let cache_dir = PathBuf::from(format!("/tmp/kreuzberg_test_empty_{:?}", thread_id));

        let _ = fs::remove_dir_all(&cache_dir);

        fs::create_dir_all(&cache_dir).expect("Failed to create cache directory");

        let cache_dir_str = cache_dir.to_str().expect("Cache dir must be valid UTF-8");
        let result = kreuzberg::cache::clear_cache_directory(cache_dir_str);

        assert!(result.is_ok(), "Should handle empty directory");
        let (removed, freed) = result.unwrap();
        assert_eq!(removed, 0, "Should remove 0 files from empty directory");
        assert_eq!(freed, 0.0, "Should free 0 MB from empty directory");

        let _ = fs::remove_dir_all(&cache_dir);
    }

    #[test]
    fn test_image_extraction_config_conversion() {
        let config = ImageExtractionConfig {
            extract_images: true,
            target_dpi: 300,
            max_image_dimension: 4096,
            auto_adjust_dpi: true,
            min_dpi: 72,
            max_dpi: 600,
        };

        assert!(config.extract_images);
        assert_eq!(config.target_dpi, 300);
        assert_eq!(config.max_image_dimension, 4096);
        assert!(config.auto_adjust_dpi);
        assert_eq!(config.min_dpi, 72);
        assert_eq!(config.max_dpi, 600);
    }

    #[test]
    fn test_image_preprocessing_config_conversion() {
        let config = ImagePreprocessingConfig {
            target_dpi: 300,
            auto_rotate: true,
            deskew: true,
            denoise: false,
            contrast_enhance: false,
            binarization_method: "otsu".to_string(),
            invert_colors: false,
        };

        assert_eq!(config.target_dpi, 300);
        assert!(config.auto_rotate);
        assert!(config.deskew);
        assert!(!config.denoise);
        assert!(!config.contrast_enhance);
        assert_eq!(config.binarization_method, "otsu");
        assert!(!config.invert_colors);
    }

    #[test]
    fn test_postprocessor_config_conversion() {
        let config = PostProcessorConfig {
            enabled: true,
            enabled_processors: Some(vec!["processor1".to_string(), "processor2".to_string()]),
            disabled_processors: None,
        };

        assert!(config.enabled);
        assert!(config.enabled_processors.is_some());
        assert_eq!(config.enabled_processors.unwrap().len(), 2);
        assert!(config.disabled_processors.is_none());
    }

    #[test]
    fn test_token_reduction_config_conversion() {
        let config = TokenReductionConfig {
            mode: "moderate".to_string(),
            preserve_important_words: true,
        };

        assert_eq!(config.mode, "moderate");
        assert!(config.preserve_important_words);
    }

    #[test]
    fn test_extraction_config_with_new_fields() {
        let mut config = ExtractionConfig::default();

        config.images = Some(ImageExtractionConfig {
            extract_images: true,
            target_dpi: 300,
            max_image_dimension: 4096,
            auto_adjust_dpi: true,
            min_dpi: 72,
            max_dpi: 600,
        });

        config.postprocessor = Some(PostProcessorConfig {
            enabled: true,
            enabled_processors: None,
            disabled_processors: None,
        });

        config.token_reduction = Some(TokenReductionConfig {
            mode: "light".to_string(),
            preserve_important_words: true,
        });

        assert!(config.images.is_some());
        assert!(config.postprocessor.is_some());
        assert!(config.token_reduction.is_some());
    }
}
