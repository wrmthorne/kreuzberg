//! New aggregation module for benchmark results
//!
//! This module provides aggregation functions that group results by:
//! - Framework and mode (single/batch)
//! - File type
//! - OCR usage (yes/no)
//!
//! Calculates percentile-based statistics for better understanding of performance distributions.

use crate::types::{BenchmarkResult, DiskSizeInfo};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Consolidated results using new aggregation format
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NewConsolidatedResults {
    /// Schema version for this output format
    pub schema_version: String,
    /// Aggregated results grouped by framework:mode combination
    pub by_framework_mode: HashMap<String, FrameworkModeAggregation>,
    /// Disk sizes for each framework
    pub disk_sizes: HashMap<String, DiskSizeInfo>,
    /// Cross-framework comparison rankings
    pub comparison: ComparisonData,
    /// Metadata about the consolidation
    pub metadata: ConsolidationMetadata,
}

/// Cross-framework comparison rankings and deltas
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ComparisonData {
    /// Frameworks ranked by median duration (fastest first)
    pub performance_ranking: Vec<RankedFramework>,
    /// Frameworks ranked by median throughput (highest first)
    pub throughput_ranking: Vec<RankedFramework>,
    /// Frameworks ranked by median memory usage (lowest first)
    pub memory_ranking: Vec<RankedFramework>,
    /// Frameworks ranked by quality score (highest first)
    pub quality_ranking: Vec<RankedFramework>,
    /// Performance deltas relative to the fastest framework
    pub deltas_vs_baseline: HashMap<String, DeltaMetrics>,
}

/// A framework entry in a ranking
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RankedFramework {
    /// Framework:mode key (e.g., "kreuzberg-rust:single")
    pub framework_mode: String,
    /// Rank (1-based)
    pub rank: usize,
    /// The metric value used for ranking
    pub value: f64,
    /// Ratio relative to the best in this ranking (1.0 = best)
    pub relative: f64,
}

/// Performance deltas relative to baseline (fastest framework)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeltaMetrics {
    /// Duration delta in ms (positive = slower)
    pub duration_delta_ms: f64,
    /// Duration delta as percentage
    pub duration_delta_percent: f64,
    /// Throughput delta in MB/s (negative = slower)
    pub throughput_delta_mbs: f64,
    /// Throughput delta as percentage
    pub throughput_delta_percent: f64,
    /// Memory delta in MB (positive = more)
    pub memory_delta_mb: f64,
    /// Memory delta as percentage
    pub memory_delta_percent: f64,
}

/// Metadata about the consolidation process
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConsolidationMetadata {
    /// Number of benchmark results included
    pub total_results: usize,
    /// Number of unique frameworks
    pub framework_count: usize,
    /// Number of unique file types
    pub file_type_count: usize,
    /// Timestamp of consolidation
    pub timestamp: String,
}

/// Aggregated results for a specific framework and mode combination
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FrameworkModeAggregation {
    /// Framework name (base name without mode suffix)
    pub framework: String,
    /// Mode: "single", "batch", "sync", "async"
    pub mode: String,
    /// Cold start duration statistics (if available)
    pub cold_start: Option<DurationPercentiles>,
    /// Results grouped by file type
    pub by_file_type: HashMap<String, FileTypeAggregation>,
}

/// Aggregated results for a specific file type
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileTypeAggregation {
    /// File type (extension)
    pub file_type: String,
    /// Results without OCR
    pub no_ocr: Option<PerformancePercentiles>,
    /// Results with OCR
    pub with_ocr: Option<PerformancePercentiles>,
}

/// Performance percentiles for a group of results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformancePercentiles {
    /// Number of successful samples used for percentile calculations
    pub successful_sample_count: usize,
    /// Total number of samples in this group (including failed)
    pub total_sample_count: usize,
    /// Throughput percentiles (p50, p95, p99) in MB/s
    pub throughput: Percentiles,
    /// Memory percentiles (p50, p95, p99) in MB
    pub memory: Percentiles,
    /// Duration percentiles (p50, p95, p99) in ms
    pub duration: Percentiles,
    /// Success rate as percentage (0-100)
    pub success_rate_percent: f64,
    /// Extraction duration percentiles (p50, p95, p99) in ms
    #[serde(skip_serializing_if = "Option::is_none")]
    pub extraction_duration: Option<Percentiles>,
    /// Quality score percentiles (p50, p95, p99) — 0.0 to 1.0
    #[serde(skip_serializing_if = "Option::is_none")]
    pub quality: Option<QualityPercentiles>,
}

/// Quality percentile values
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QualityPercentiles {
    /// Median F1 text score
    pub f1_text_p50: f64,
    /// Median F1 numeric score
    pub f1_numeric_p50: f64,
    /// Median overall quality score
    pub quality_score_p50: f64,
}

/// Percentile values for a metric
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Percentiles {
    /// 50th percentile (median)
    pub p50: f64,
    /// 95th percentile
    pub p95: f64,
    /// 99th percentile
    pub p99: f64,
}

/// Duration percentiles in milliseconds
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DurationPercentiles {
    /// Number of samples with cold start data
    pub sample_count: usize,
    /// 50th percentile (median) in ms
    pub p50_ms: f64,
    /// 95th percentile in ms
    pub p95_ms: f64,
    /// 99th percentile in ms
    pub p99_ms: f64,
}

/// Main aggregation function for new format
///
/// Groups results by:
/// 1. Framework and mode (extracted from framework name)
/// 2. File type (extension)
/// 3. OCR usage (yes/no)
///
/// Calculates p50/p95/p99 percentiles for each group.
pub fn aggregate_new_format(results: &[BenchmarkResult]) -> NewConsolidatedResults {
    // Validate input - HIGH PRIORITY FIX
    if results.is_empty() {
        return NewConsolidatedResults {
            schema_version: "2.0.0".to_string(),
            by_framework_mode: HashMap::new(),
            disk_sizes: HashMap::new(),
            comparison: ComparisonData {
                performance_ranking: Vec::new(),
                throughput_ranking: Vec::new(),
                memory_ranking: Vec::new(),
                quality_ranking: Vec::new(),
                deltas_vs_baseline: HashMap::new(),
            },
            metadata: ConsolidationMetadata {
                total_results: 0,
                framework_count: 0,
                file_type_count: 0,
                timestamp: chrono::Utc::now().to_rfc3339(),
            },
        };
    }

    let mut by_framework_mode: HashMap<String, HashMap<String, Vec<&BenchmarkResult>>> = HashMap::new();
    let mut disk_sizes: HashMap<String, DiskSizeInfo> = HashMap::new();
    let mut file_types = std::collections::HashSet::new();

    // Group results by framework:mode and file type
    for result in results {
        let (framework, mode) = extract_framework_and_mode(&result.framework);
        let key = format!("{}:{}", framework, mode);

        by_framework_mode
            .entry(key)
            .or_default()
            .entry(result.file_extension.clone())
            .or_default()
            .push(result);

        file_types.insert(result.file_extension.clone());

        // Collect disk sizes
        if let Some(disk_size) = &result.framework_capabilities.installation_size {
            disk_sizes.insert(framework.to_string(), disk_size.clone());
        }
    }

    // Aggregate each framework:mode combination
    let mut aggregated_by_framework_mode = HashMap::new();

    for (framework_mode_key, file_type_results) in by_framework_mode {
        let parts: Vec<&str> = framework_mode_key.split(':').collect();
        let framework = parts[0].to_string();
        let mode = parts[1].to_string();

        // Collect all results for this framework:mode for cold start calculation
        let all_results: Vec<&BenchmarkResult> = file_type_results.values().flat_map(|v| v.iter().copied()).collect();
        let cold_start = aggregate_cold_starts(&all_results);

        // Aggregate by file type
        let mut by_file_type = HashMap::new();
        for (file_type, results_for_type) in file_type_results {
            let aggregation = aggregate_by_ocr_status(&results_for_type);
            by_file_type.insert(
                file_type.clone(),
                FileTypeAggregation {
                    file_type: file_type.clone(),
                    no_ocr: aggregation.0,
                    with_ocr: aggregation.1,
                },
            );
        }

        aggregated_by_framework_mode.insert(
            framework_mode_key.clone(),
            FrameworkModeAggregation {
                framework,
                mode,
                cold_start,
                by_file_type,
            },
        );
    }

    let metadata = ConsolidationMetadata {
        total_results: results.len(),
        framework_count: aggregated_by_framework_mode.len(),
        file_type_count: file_types.len(),
        timestamp: chrono::Utc::now().to_rfc3339(),
    };

    let comparison = build_comparison(&aggregated_by_framework_mode);

    NewConsolidatedResults {
        schema_version: "2.0.0".to_string(),
        by_framework_mode: aggregated_by_framework_mode,
        disk_sizes,
        comparison,
        metadata,
    }
}

/// Aggregate results by OCR status
///
/// Returns (no_ocr, with_ocr) tuple of PerformancePercentiles
fn aggregate_by_ocr_status(
    results: &[&BenchmarkResult],
) -> (Option<PerformancePercentiles>, Option<PerformancePercentiles>) {
    use crate::types::OcrStatus;

    // OCR status grouping:
    // - OcrStatus::Used → "with_ocr" group
    // - OcrStatus::NotUsed → "no_ocr" group
    // - OcrStatus::Unknown → "no_ocr" group (fallback; unknown is conservatively treated as non-OCR)
    let no_ocr: Vec<&BenchmarkResult> = results
        .iter()
        .filter(|r| r.ocr_status != OcrStatus::Used)
        .copied()
        .collect();

    let with_ocr: Vec<&BenchmarkResult> = results
        .iter()
        .filter(|r| r.ocr_status == OcrStatus::Used)
        .copied()
        .collect();

    let no_ocr_stats = if !no_ocr.is_empty() {
        Some(calculate_percentiles(&no_ocr))
    } else {
        None
    };

    let with_ocr_stats = if !with_ocr.is_empty() {
        Some(calculate_percentiles(&with_ocr))
    } else {
        None
    };

    (no_ocr_stats, with_ocr_stats)
}

/// Calculate percentiles for a group of results
///
/// Only uses successful results for metric calculations.
/// Success rate is calculated from all results.
fn calculate_percentiles(results: &[&BenchmarkResult]) -> PerformancePercentiles {
    let successful: Vec<&BenchmarkResult> = results.iter().filter(|r| r.success).copied().collect();

    // Extract values for percentile calculation with NaN filtering - HIGH PRIORITY FIX
    let mut durations: Vec<f64> = successful
        .iter()
        .map(|r| r.duration.as_secs_f64() * 1000.0)
        .filter(|&v| !v.is_nan() && v.is_finite())
        .collect();

    let mut throughputs: Vec<f64> = successful
        .iter()
        .map(|r| r.metrics.throughput_bytes_per_sec / 1_000_000.0) // Convert to MB/s
        .filter(|&v| v > 0.0 && v.is_finite()) // Filter zero values (invalid measurements)
        .collect();

    let mut memories: Vec<f64> = successful
        .iter()
        .map(|r| r.metrics.peak_memory_bytes as f64 / 1_000_000.0) // Convert to MB
        .filter(|&v| !v.is_nan() && v.is_finite())
        .collect();

    let mut extraction_durations: Vec<f64> = successful
        .iter()
        .filter_map(|r| r.extraction_duration.map(|d| d.as_secs_f64() * 1000.0))
        .filter(|&v| !v.is_nan() && v.is_finite())
        .collect();

    // Sort for percentile calculation (NaN-safe)
    durations.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
    throughputs.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
    memories.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
    extraction_durations.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));

    // Build percentiles with NaN/Inf validation
    let duration = Percentiles {
        p50: sanitize_f64(calculate_percentile_value(&durations, 0.50)),
        p95: sanitize_f64(calculate_percentile_value(&durations, 0.95)),
        p99: sanitize_f64(calculate_percentile_value(&durations, 0.99)),
    };

    let throughput = Percentiles {
        p50: sanitize_f64(calculate_percentile_value(&throughputs, 0.50)),
        p95: sanitize_f64(calculate_percentile_value(&throughputs, 0.95)),
        p99: sanitize_f64(calculate_percentile_value(&throughputs, 0.99)),
    };

    let memory = Percentiles {
        p50: sanitize_f64(calculate_percentile_value(&memories, 0.50)),
        p95: sanitize_f64(calculate_percentile_value(&memories, 0.95)),
        p99: sanitize_f64(calculate_percentile_value(&memories, 0.99)),
    };

    let extraction_duration = if !extraction_durations.is_empty() {
        Some(Percentiles {
            p50: sanitize_f64(calculate_percentile_value(&extraction_durations, 0.50)),
            p95: sanitize_f64(calculate_percentile_value(&extraction_durations, 0.95)),
            p99: sanitize_f64(calculate_percentile_value(&extraction_durations, 0.99)),
        })
    } else {
        None
    };

    let success_rate_percent = if !results.is_empty() {
        (successful.len() as f64 / results.len() as f64) * 100.0
    } else {
        0.0
    };

    // Quality percentiles
    let quality = {
        let mut f1_texts: Vec<f64> = successful
            .iter()
            .filter_map(|r| r.quality.as_ref().map(|q| q.f1_score_text))
            .filter(|v| !v.is_nan() && v.is_finite())
            .collect();
        let mut f1_numerics: Vec<f64> = successful
            .iter()
            .filter_map(|r| r.quality.as_ref().map(|q| q.f1_score_numeric))
            .filter(|v| !v.is_nan() && v.is_finite())
            .collect();
        let mut quality_scores: Vec<f64> = successful
            .iter()
            .filter_map(|r| r.quality.as_ref().map(|q| q.quality_score))
            .filter(|v| !v.is_nan() && v.is_finite())
            .collect();

        if !quality_scores.is_empty() {
            f1_texts.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
            f1_numerics.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
            quality_scores.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));

            Some(QualityPercentiles {
                f1_text_p50: sanitize_f64(calculate_percentile_value(&f1_texts, 0.50)),
                f1_numeric_p50: sanitize_f64(calculate_percentile_value(&f1_numerics, 0.50)),
                quality_score_p50: sanitize_f64(calculate_percentile_value(&quality_scores, 0.50)),
            })
        } else {
            None
        }
    };

    PerformancePercentiles {
        successful_sample_count: successful.len(), // CRITICAL FIX: Count only successful results used for percentiles
        total_sample_count: results.len(),
        throughput,
        memory,
        duration,
        success_rate_percent,
        extraction_duration,
        quality,
    }
}

/// Aggregate cold start durations
///
/// Returns percentiles of cold start durations if any results have cold start data.
fn aggregate_cold_starts(results: &[&BenchmarkResult]) -> Option<DurationPercentiles> {
    let cold_starts: Vec<f64> = results
        .iter()
        .filter_map(|r| r.cold_start_duration.map(|d| d.as_secs_f64() * 1000.0))
        .filter(|&v| !v.is_nan() && v.is_finite()) // HIGH PRIORITY FIX: NaN filtering
        .collect();

    if cold_starts.is_empty() {
        return None;
    }

    let mut sorted = cold_starts.clone();
    sorted.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));

    Some(DurationPercentiles {
        sample_count: cold_starts.len(),
        p50_ms: sanitize_f64(calculate_percentile_value(&sorted, 0.50)),
        p95_ms: sanitize_f64(calculate_percentile_value(&sorted, 0.95)),
        p99_ms: sanitize_f64(calculate_percentile_value(&sorted, 0.99)),
    })
}

/// Extract framework name and mode from framework string
///
/// Framework naming convention: {base}-{variant}-{mode}
/// Examples: kreuzberg-rust, kreuzberg-python-sync, kreuzberg-python-batch
/// Variants: -sync, -async (mapped to "single" mode)
/// Modes: -batch (mapped to "batch" mode), absence (mapped to "single" mode)
///
/// Returns (framework_name, mode) where mode is one of:
/// - "batch" if ends with "-batch"
/// - "single" otherwise (default)
///
/// The -sync/-async suffixes are stripped for aggregation because we unify
/// implementations per language — sync vs async is a language-specific detail.
fn extract_framework_and_mode(framework_name: &str) -> (&str, &str) {
    // First, check and strip -batch suffix (mode indicator)
    if let Some(base) = framework_name.strip_suffix("-batch") {
        // Then strip -sync/-async suffixes from the base (implementation details)
        let normalized = base
            .strip_suffix("-sync")
            .or_else(|| base.strip_suffix("-async"))
            .unwrap_or(base);
        (normalized, "batch")
    } else {
        // No -batch suffix, so check and strip -sync/-async suffixes (implementation details)
        let normalized = framework_name
            .strip_suffix("-sync")
            .or_else(|| framework_name.strip_suffix("-async"))
            .unwrap_or(framework_name);
        (normalized, "single")
    }
}

/// Build cross-framework comparison rankings from aggregated data
fn build_comparison(by_framework_mode: &HashMap<String, FrameworkModeAggregation>) -> ComparisonData {
    // Collect median metrics per framework:mode by averaging across file types
    let mut metrics: Vec<(String, f64, f64, f64, f64)> = Vec::new(); // (key, duration_p50, throughput_p50, memory_p50, quality_p50)

    for (key, agg) in by_framework_mode {
        let mut durations = Vec::new();
        let mut throughputs = Vec::new();
        let mut memories = Vec::new();
        let mut qualities = Vec::new();

        for ft in agg.by_file_type.values() {
            for perf in [&ft.no_ocr, &ft.with_ocr].into_iter().flatten() {
                durations.push(perf.duration.p50);
                throughputs.push(perf.throughput.p50);
                memories.push(perf.memory.p50);
                if let Some(q) = &perf.quality {
                    qualities.push(q.quality_score_p50);
                }
            }
        }

        if durations.is_empty() {
            continue;
        }

        let avg = |v: &[f64]| -> f64 {
            if v.is_empty() {
                f64::NAN
            } else {
                v.iter().sum::<f64>() / v.len() as f64
            }
        };

        metrics.push((
            key.clone(),
            avg(&durations),
            avg(&throughputs),
            avg(&memories),
            avg(&qualities),
        ));
    }

    // Performance ranking (lower duration = better, rank 1)
    let mut perf = metrics.clone();
    perf.retain(|m| m.1.is_finite()); // Filter out NaN quality scores
    perf.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
    let baseline_dur = perf.first().map(|r| r.1).unwrap_or(1.0);
    let performance_ranking: Vec<RankedFramework> = perf
        .iter()
        .enumerate()
        .map(|(i, (k, v, ..))| RankedFramework {
            framework_mode: k.clone(),
            rank: i + 1,
            value: *v,
            relative: if baseline_dur > 0.0 { *v / baseline_dur } else { 1.0 },
        })
        .collect();

    // Throughput ranking (higher = better)
    let mut thr = metrics.clone();
    thr.retain(|m| m.2.is_finite()); // Filter out NaN throughput values
    thr.sort_by(|a, b| b.2.partial_cmp(&a.2).unwrap_or(std::cmp::Ordering::Equal));
    let baseline_thr = thr.first().map(|r| r.2).unwrap_or(1.0);
    let throughput_ranking: Vec<RankedFramework> = thr
        .iter()
        .enumerate()
        .map(|(i, (k, _, v, ..))| RankedFramework {
            framework_mode: k.clone(),
            rank: i + 1,
            value: *v,
            relative: if baseline_thr > 0.0 { *v / baseline_thr } else { 1.0 },
        })
        .collect();

    // Memory ranking (lower = better)
    let mut mem = metrics.clone();
    mem.retain(|m| m.3.is_finite()); // Filter out NaN memory values
    mem.sort_by(|a, b| a.3.partial_cmp(&b.3).unwrap_or(std::cmp::Ordering::Equal));
    let baseline_mem = mem.first().map(|r| r.3).unwrap_or(1.0);
    let memory_ranking: Vec<RankedFramework> = mem
        .iter()
        .enumerate()
        .map(|(i, (k, _, _, v, _))| RankedFramework {
            framework_mode: k.clone(),
            rank: i + 1,
            value: *v,
            relative: if baseline_mem > 0.0 { *v / baseline_mem } else { 1.0 },
        })
        .collect();

    // Quality ranking (higher = better)
    let mut qual = metrics.clone();
    qual.retain(|m| m.4.is_finite()); // Filter out NaN quality scores
    qual.sort_by(|a, b| b.4.partial_cmp(&a.4).unwrap_or(std::cmp::Ordering::Equal));
    let baseline_qual = qual.first().map(|r| r.4).unwrap_or(1.0);
    let quality_ranking: Vec<RankedFramework> = qual
        .iter()
        .enumerate()
        .map(|(i, (k, _, _, _, v))| RankedFramework {
            framework_mode: k.clone(),
            rank: i + 1,
            value: *v,
            relative: if baseline_qual > 0.0 { *v / baseline_qual } else { 1.0 },
        })
        .collect();

    // Deltas vs baseline (fastest framework)
    let mut deltas_vs_baseline = HashMap::new();
    if let Some(baseline) = metrics
        .iter()
        .min_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal))
    {
        for (k, dur, thr, mem_val, _) in &metrics {
            if k != &baseline.0 {
                deltas_vs_baseline.insert(
                    k.clone(),
                    DeltaMetrics {
                        duration_delta_ms: dur - baseline.1,
                        duration_delta_percent: if baseline.1 > 0.0 {
                            ((dur - baseline.1) / baseline.1) * 100.0
                        } else {
                            0.0
                        },
                        throughput_delta_mbs: thr - baseline.2,
                        throughput_delta_percent: if baseline.2 > 0.0 {
                            ((thr - baseline.2) / baseline.2) * 100.0
                        } else {
                            0.0
                        },
                        memory_delta_mb: mem_val - baseline.3,
                        memory_delta_percent: if baseline.3 > 0.0 {
                            ((mem_val - baseline.3) / baseline.3) * 100.0
                        } else {
                            0.0
                        },
                    },
                );
            }
        }
    }

    ComparisonData {
        performance_ranking,
        throughput_ranking,
        memory_ranking,
        quality_ranking,
        deltas_vs_baseline,
    }
}

/// Sanitize f64 value, replacing NaN or infinity with 0.0
fn sanitize_f64(v: f64) -> f64 {
    if v.is_finite() { v } else { 0.0 }
}

/// Calculate a specific percentile from sorted values using linear interpolation
///
/// Uses R-7 method (NumPy default) for accurate percentile calculation.
/// Returns 0.0 for empty arrays.
fn calculate_percentile_value(sorted_values: &[f64], percentile: f64) -> f64 {
    if sorted_values.is_empty() {
        return 0.0;
    }

    let n = sorted_values.len();
    if n == 1 {
        return sorted_values[0];
    }

    // Linear interpolation (R-7 method, used by NumPy) - CRITICAL FIX
    let index = percentile * (n as f64 - 1.0);
    let lower = index.floor() as usize;
    let mut upper = index.ceil() as usize;

    // Bounds check: upper never exceeds array length
    upper = upper.min(sorted_values.len() - 1);

    if lower == upper {
        sorted_values[lower]
    } else {
        let weight = index - lower as f64;
        sorted_values[lower] * (1.0 - weight) + sorted_values[upper] * weight
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::types::{FrameworkCapabilities, OcrStatus, PerformanceMetrics};
    use std::path::PathBuf;
    use std::time::Duration;

    fn create_test_result(
        framework: &str,
        file_ext: &str,
        ocr_status: OcrStatus,
        duration_ms: u64,
        throughput_bps: f64,
        memory_bytes: u64,
    ) -> BenchmarkResult {
        BenchmarkResult {
            framework: framework.to_string(),
            file_path: PathBuf::from(format!("test.{}", file_ext)),
            file_size: 1024,
            success: true,
            error_message: None,
            duration: Duration::from_millis(duration_ms),
            extraction_duration: None,
            subprocess_overhead: None,
            metrics: PerformanceMetrics {
                peak_memory_bytes: memory_bytes,
                avg_cpu_percent: 50.0,
                throughput_bytes_per_sec: throughput_bps,
                p50_memory_bytes: memory_bytes,
                p95_memory_bytes: memory_bytes,
                p99_memory_bytes: memory_bytes,
            },
            quality: None,
            iterations: vec![],
            statistics: None,
            cold_start_duration: Some(Duration::from_millis(500)),
            file_extension: file_ext.to_string(),
            framework_capabilities: FrameworkCapabilities::default(),
            pdf_metadata: None,
            ocr_status,
            extracted_text: None,
        }
    }

    #[test]
    fn test_extract_framework_and_mode() {
        // Sync/async suffixes are normalized to "single" mode
        assert_eq!(extract_framework_and_mode("kreuzberg-sync"), ("kreuzberg", "single"));
        assert_eq!(extract_framework_and_mode("kreuzberg-async"), ("kreuzberg", "single"));
        assert_eq!(extract_framework_and_mode("python-sync"), ("python", "single"));
        assert_eq!(extract_framework_and_mode("python-async"), ("python", "single"));

        // Batch mode is preserved
        assert_eq!(extract_framework_and_mode("kreuzberg-batch"), ("kreuzberg", "batch"));
        assert_eq!(extract_framework_and_mode("python-batch"), ("python", "batch"));

        // No suffix defaults to single mode
        assert_eq!(extract_framework_and_mode("kreuzberg"), ("kreuzberg", "single"));
        assert_eq!(extract_framework_and_mode("docling"), ("docling", "single"));
    }

    #[test]
    fn test_calculate_percentile_value() {
        let values = vec![1.0, 2.0, 3.0, 4.0, 5.0];
        assert_eq!(calculate_percentile_value(&values, 0.0), 1.0);
        assert_eq!(calculate_percentile_value(&values, 0.5), 3.0);
        assert_eq!(calculate_percentile_value(&values, 1.0), 5.0);
        assert_eq!(calculate_percentile_value(&[], 0.5), 0.0);
    }

    #[test]
    fn test_aggregate_new_format() {
        let results = vec![
            create_test_result(
                "kreuzberg-sync",
                "pdf",
                OcrStatus::NotUsed,
                100,
                1_000_000.0,
                10_000_000,
            ),
            create_test_result("kreuzberg-sync", "pdf", OcrStatus::Used, 200, 500_000.0, 20_000_000),
            create_test_result(
                "kreuzberg-batch",
                "docx",
                OcrStatus::NotUsed,
                150,
                750_000.0,
                15_000_000,
            ),
        ];

        let aggregated = aggregate_new_format(&results);

        assert_eq!(aggregated.by_framework_mode.len(), 2);
        // "kreuzberg-sync" is normalized to "kreuzberg:single"
        assert!(aggregated.by_framework_mode.contains_key("kreuzberg:single"));
        assert!(aggregated.by_framework_mode.contains_key("kreuzberg:batch"));

        let single_agg = &aggregated.by_framework_mode["kreuzberg:single"];
        assert_eq!(single_agg.framework, "kreuzberg");
        assert_eq!(single_agg.mode, "single");
        assert!(single_agg.cold_start.is_some());

        let pdf_agg = &single_agg.by_file_type["pdf"];
        assert!(pdf_agg.no_ocr.is_some());
        assert!(pdf_agg.with_ocr.is_some());

        assert_eq!(pdf_agg.no_ocr.as_ref().unwrap().successful_sample_count, 1);
        assert_eq!(pdf_agg.with_ocr.as_ref().unwrap().successful_sample_count, 1);
    }

    #[test]
    fn test_calculate_percentiles() {
        let results = [
            create_test_result("kreuzberg", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000),
            create_test_result("kreuzberg", "pdf", OcrStatus::NotUsed, 200, 2_000_000.0, 20_000_000),
            create_test_result("kreuzberg", "pdf", OcrStatus::NotUsed, 300, 3_000_000.0, 30_000_000),
        ];

        let refs: Vec<&BenchmarkResult> = results.iter().collect();
        let percentiles = calculate_percentiles(&refs);

        assert_eq!(percentiles.successful_sample_count, 3);
        assert_eq!(percentiles.total_sample_count, 3);
        assert_eq!(percentiles.success_rate_percent, 100.0);
        assert!(percentiles.duration.p50 > 0.0);
        assert!(percentiles.throughput.p50 > 0.0);
        assert!(percentiles.memory.p50 > 0.0);
    }

    #[test]
    fn test_aggregate_cold_starts() {
        let results = [
            create_test_result("kreuzberg", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000),
            create_test_result("kreuzberg", "pdf", OcrStatus::NotUsed, 200, 2_000_000.0, 20_000_000),
        ];

        let refs: Vec<&BenchmarkResult> = results.iter().collect();
        let cold_starts = aggregate_cold_starts(&refs);

        assert!(cold_starts.is_some());
        let cold_starts = cold_starts.unwrap();
        assert_eq!(cold_starts.sample_count, 2);
        assert!(cold_starts.p50_ms > 0.0);
    }

    #[test]
    fn test_ocr_unknown_handling() {
        // Test that Unknown OCR status is handled correctly
        let results = vec![BenchmarkResult {
            framework: "test-framework".to_string(),
            file_path: PathBuf::from("/tmp/test1.pdf"),
            file_size: 1024,
            success: true,
            error_message: None,
            duration: Duration::from_millis(100),
            extraction_duration: None,
            subprocess_overhead: None,
            metrics: PerformanceMetrics {
                peak_memory_bytes: 10_000_000,
                avg_cpu_percent: 50.0,
                throughput_bytes_per_sec: 10_240.0,
                p50_memory_bytes: 8_000_000,
                p95_memory_bytes: 9_500_000,
                p99_memory_bytes: 9_900_000,
            },
            quality: None,
            iterations: vec![],
            statistics: None,
            cold_start_duration: Some(Duration::from_millis(200)),
            file_extension: "pdf".to_string(),
            framework_capabilities: Default::default(),
            pdf_metadata: None,
            ocr_status: OcrStatus::Unknown, // Unknown status
            extracted_text: None,
        }];

        let aggregated = aggregate_new_format(&results);

        // Unknown should be in no_ocr group
        let framework_mode = aggregated.by_framework_mode.get("test-framework:single").unwrap();
        let file_type = framework_mode.by_file_type.get("pdf").unwrap();
        assert!(file_type.no_ocr.is_some());
        assert_eq!(file_type.no_ocr.as_ref().unwrap().successful_sample_count, 1);
    }

    #[test]
    fn test_failed_results_excluded_from_percentiles() {
        // Test that failed results don't affect percentile calculations
        let results = vec![
            BenchmarkResult {
                framework: "test-framework".to_string(),
                file_path: PathBuf::from("/tmp/test1.pdf"),
                file_size: 1024,
                success: true,
                error_message: None,
                duration: Duration::from_millis(100),
                extraction_duration: None,
                subprocess_overhead: None,
                metrics: PerformanceMetrics {
                    peak_memory_bytes: 10_000_000,
                    avg_cpu_percent: 50.0,
                    throughput_bytes_per_sec: 10_240.0,
                    p50_memory_bytes: 8_000_000,
                    p95_memory_bytes: 9_500_000,
                    p99_memory_bytes: 9_900_000,
                },
                quality: None,
                iterations: vec![],
                statistics: None,
                cold_start_duration: None,
                file_extension: "pdf".to_string(),
                framework_capabilities: Default::default(),
                pdf_metadata: None,
                ocr_status: OcrStatus::NotUsed,
                extracted_text: None,
            },
            BenchmarkResult {
                framework: "test-framework".to_string(),
                file_path: PathBuf::from("/tmp/test2.pdf"),
                file_size: 2048,
                success: false, // Failed result
                error_message: Some("Test error".to_string()),
                duration: Duration::from_secs(0),
                extraction_duration: None,
                subprocess_overhead: None,
                metrics: PerformanceMetrics {
                    peak_memory_bytes: 0,
                    avg_cpu_percent: 0.0,
                    throughput_bytes_per_sec: 0.0,
                    p50_memory_bytes: 0,
                    p95_memory_bytes: 0,
                    p99_memory_bytes: 0,
                },
                quality: None,
                iterations: vec![],
                statistics: None,
                cold_start_duration: None,
                file_extension: "pdf".to_string(),
                framework_capabilities: Default::default(),
                pdf_metadata: None,
                ocr_status: OcrStatus::NotUsed,
                extracted_text: None,
            },
        ];

        let aggregated = aggregate_new_format(&results);

        let framework_mode = aggregated.by_framework_mode.get("test-framework:single").unwrap();
        let file_type = framework_mode.by_file_type.get("pdf").unwrap();
        let no_ocr = file_type.no_ocr.as_ref().unwrap();

        // successful_sample_count should only count successful results
        assert_eq!(no_ocr.successful_sample_count, 1);
        assert_eq!(no_ocr.total_sample_count, 2);
        // success_rate_percent should account for all results
        assert_eq!(no_ocr.success_rate_percent, 50.0); // 1 success / 2 total = 50%
        // Percentiles based on 1 successful result
        assert_eq!(no_ocr.duration.p50, 100.0);
    }

    #[test]
    fn test_empty_input() {
        let results: Vec<BenchmarkResult> = vec![];
        let aggregated = aggregate_new_format(&results);

        assert_eq!(aggregated.by_framework_mode.len(), 0);
        assert_eq!(aggregated.metadata.total_results, 0);
    }

    #[test]
    fn test_percentile_interpolation() {
        // Test that p95 with [1,2,3,4,5] uses interpolation
        let sorted = vec![1.0, 2.0, 3.0, 4.0, 5.0];
        let p95 = calculate_percentile_value(&sorted, 0.95);

        // With linear interpolation: index = 0.95 * 4 = 3.8
        // Result = values[3] * 0.2 + values[4] * 0.8 = 4.0 * 0.2 + 5.0 * 0.8 = 4.8
        assert!((p95 - 4.8).abs() < 0.01);
    }

    // ============================================================================
    // Tests for extraction_duration aggregation in new format
    // ============================================================================

    #[test]
    fn test_calculate_percentiles_extraction_duration_all_present() {
        // Test: All results have extraction_duration -> percentiles populated
        let mut result1 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000);
        result1.extraction_duration = Some(Duration::from_millis(80));

        let mut result2 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 150, 1_000_000.0, 10_000_000);
        result2.extraction_duration = Some(Duration::from_millis(120));

        let mut result3 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 200, 1_000_000.0, 10_000_000);
        result3.extraction_duration = Some(Duration::from_millis(160));

        let refs = vec![&result1, &result2, &result3];
        let percentiles = calculate_percentiles(&refs);

        assert!(percentiles.extraction_duration.is_some());
        let ext_dur = percentiles.extraction_duration.as_ref().unwrap();
        assert!((ext_dur.p50 - 120.0).abs() < 0.1); // median: 120
        assert!(ext_dur.p95 > 120.0); // p95 should be between 120 and 160
        assert!(ext_dur.p95 <= 160.0);
    }

    #[test]
    fn test_calculate_percentiles_extraction_duration_all_none() {
        // Test: All results have extraction_duration = None -> extraction_duration None
        let result1 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000);
        let result2 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 150, 1_000_000.0, 10_000_000);
        let result3 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 200, 1_000_000.0, 10_000_000);

        let refs = vec![&result1, &result2, &result3];
        let percentiles = calculate_percentiles(&refs);

        assert!(percentiles.extraction_duration.is_none());
    }

    #[test]
    fn test_calculate_percentiles_extraction_duration_mixed() {
        // Test: Mixed Some/None extraction_duration -> only Some values used
        let mut result1 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000);
        result1.extraction_duration = Some(Duration::from_millis(80));

        let result2 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 150, 1_000_000.0, 10_000_000);
        // result2.extraction_duration = None

        let mut result3 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 200, 1_000_000.0, 10_000_000);
        result3.extraction_duration = Some(Duration::from_millis(160));

        let refs = vec![&result1, &result2, &result3];
        let percentiles = calculate_percentiles(&refs);

        assert!(percentiles.extraction_duration.is_some());
        let ext_dur = percentiles.extraction_duration.as_ref().unwrap();
        // Only 80 and 160 used, median should be 120
        assert!((ext_dur.p50 - 120.0).abs() < 0.1);
    }

    #[test]
    fn test_calculate_percentiles_extraction_duration_filters_invalid() {
        // Test: NaN/infinite extraction durations filtered out
        // Note: We can't directly create NaN with Duration, so we test the filtering logic
        // by ensuring valid values are correctly processed
        let mut result1 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000);
        result1.extraction_duration = Some(Duration::from_millis(80));

        let mut result2 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 150, 1_000_000.0, 10_000_000);
        result2.extraction_duration = Some(Duration::from_millis(120));

        let mut result3 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 200, 1_000_000.0, 10_000_000);
        result3.extraction_duration = Some(Duration::from_millis(160));

        let refs = vec![&result1, &result2, &result3];
        let percentiles = calculate_percentiles(&refs);

        // All values should be present and valid
        assert!(percentiles.extraction_duration.is_some());
        let ext_dur = percentiles.extraction_duration.as_ref().unwrap();
        assert!(ext_dur.p50.is_finite());
        assert!(!ext_dur.p50.is_nan());
    }

    #[test]
    fn test_calculate_percentiles_extraction_duration_with_failed_results() {
        // Test: Failed results excluded from extraction_duration calculation
        let mut result1 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000);
        result1.extraction_duration = Some(Duration::from_millis(80));

        let mut result2_failed = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 0, 0.0, 0);
        result2_failed.success = false;
        result2_failed.error_message = Some("Failed".to_string());
        result2_failed.extraction_duration = Some(Duration::from_millis(50)); // Should be ignored

        let mut result3 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 200, 1_000_000.0, 10_000_000);
        result3.extraction_duration = Some(Duration::from_millis(160));

        let refs = vec![&result1, &result2_failed, &result3];
        let percentiles = calculate_percentiles(&refs);

        // Only result1 and result3 should be used (80 and 160)
        assert!(percentiles.extraction_duration.is_some());
        let ext_dur = percentiles.extraction_duration.as_ref().unwrap();
        assert_eq!(percentiles.successful_sample_count, 2); // Only 2 successful results
        assert_eq!(percentiles.total_sample_count, 3);
        assert!((ext_dur.p50 - 120.0).abs() < 0.1); // median: 120
    }

    #[test]
    fn test_aggregate_by_ocr_status_extraction_duration() {
        // Test: Extraction duration aggregated correctly with OCR status split
        let mut result_no_ocr_1 =
            create_test_result("framework1", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000);
        result_no_ocr_1.extraction_duration = Some(Duration::from_millis(80));

        let mut result_no_ocr_2 =
            create_test_result("framework1", "pdf", OcrStatus::NotUsed, 150, 1_000_000.0, 10_000_000);
        result_no_ocr_2.extraction_duration = Some(Duration::from_millis(120));

        let mut result_with_ocr = create_test_result("framework1", "pdf", OcrStatus::Used, 300, 500_000.0, 20_000_000);
        result_with_ocr.extraction_duration = Some(Duration::from_millis(250));

        let refs = vec![&result_no_ocr_1, &result_no_ocr_2, &result_with_ocr];
        let (no_ocr, with_ocr) = aggregate_by_ocr_status(&refs);

        // No OCR group
        assert!(no_ocr.is_some());
        let no_ocr_perf = no_ocr.unwrap();
        assert!(no_ocr_perf.extraction_duration.is_some());
        assert_eq!(no_ocr_perf.extraction_duration.as_ref().unwrap().p50, 100.0); // median of [80, 120]

        // With OCR group
        assert!(with_ocr.is_some());
        let with_ocr_perf = with_ocr.unwrap();
        assert!(with_ocr_perf.extraction_duration.is_some());
        assert_eq!(with_ocr_perf.extraction_duration.as_ref().unwrap().p50, 250.0);
    }

    #[test]
    fn test_aggregate_new_format_extraction_duration_preserved() {
        // Test: aggregate_new_format preserves extraction_duration statistics
        let mut result1 = create_test_result(
            "kreuzberg-sync",
            "pdf",
            OcrStatus::NotUsed,
            100,
            1_000_000.0,
            10_000_000,
        );
        result1.extraction_duration = Some(Duration::from_millis(80));

        let mut result2 = create_test_result(
            "kreuzberg-sync",
            "pdf",
            OcrStatus::NotUsed,
            150,
            1_000_000.0,
            10_000_000,
        );
        result2.extraction_duration = Some(Duration::from_millis(120));

        let results = vec![result1, result2];
        let aggregated = aggregate_new_format(&results);

        let framework_mode = aggregated.by_framework_mode.get("kreuzberg:single").unwrap();
        let pdf_stats = framework_mode.by_file_type.get("pdf").unwrap();
        let no_ocr = pdf_stats.no_ocr.as_ref().unwrap();

        assert!(no_ocr.extraction_duration.is_some());
        let ext_dur = no_ocr.extraction_duration.as_ref().unwrap();
        assert!((ext_dur.p50 - 100.0).abs() < 0.1);
    }

    #[test]
    fn test_calculate_percentiles_extraction_duration_single_value() {
        // Test: Single extraction_duration value -> all percentiles return that value
        let mut result = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000);
        result.extraction_duration = Some(Duration::from_millis(80));

        let refs = vec![&result];
        let percentiles = calculate_percentiles(&refs);

        assert!(percentiles.extraction_duration.is_some());
        let ext_dur = percentiles.extraction_duration.as_ref().unwrap();
        assert_eq!(ext_dur.p50, 80.0);
        assert_eq!(ext_dur.p95, 80.0);
        assert_eq!(ext_dur.p99, 80.0);
    }

    #[test]
    fn test_calculate_percentiles_extraction_duration_large_dataset() {
        // Test: Large dataset with extraction_duration -> percentiles calculated correctly
        let mut results = vec![];
        for i in 1..=100 {
            let mut result =
                create_test_result("framework1", "pdf", OcrStatus::NotUsed, i * 10, 1_000_000.0, 10_000_000);
            result.extraction_duration = Some(Duration::from_millis(i * 8));
            results.push(result);
        }

        let refs: Vec<&BenchmarkResult> = results.iter().collect();
        let percentiles = calculate_percentiles(&refs);

        assert!(percentiles.extraction_duration.is_some());
        let ext_dur = percentiles.extraction_duration.as_ref().unwrap();

        // p50 (median) of 1-100 scaled by 8: around 404-408ms
        assert!(ext_dur.p50 >= 400.0 && ext_dur.p50 <= 410.0);

        // p95 should be higher than p50
        assert!(ext_dur.p95 > ext_dur.p50);

        // p99 should be higher than p95
        assert!(ext_dur.p99 > ext_dur.p95);
    }

    #[test]
    fn test_calculate_percentiles_extraction_duration_no_extraction_some_failed() {
        // Test: No extraction_duration data, some failures -> extraction_duration None
        let result1_failed = BenchmarkResult {
            framework: "test".to_string(),
            file_path: PathBuf::from("test1.pdf"),
            file_size: 1024,
            success: false,
            error_message: Some("Error".to_string()),
            duration: Duration::from_millis(0),
            extraction_duration: None,
            subprocess_overhead: None,
            metrics: PerformanceMetrics {
                peak_memory_bytes: 0,
                avg_cpu_percent: 0.0,
                throughput_bytes_per_sec: 0.0,
                p50_memory_bytes: 0,
                p95_memory_bytes: 0,
                p99_memory_bytes: 0,
            },
            quality: None,
            iterations: vec![],
            statistics: None,
            cold_start_duration: None,
            file_extension: "pdf".to_string(),
            framework_capabilities: FrameworkCapabilities::default(),
            pdf_metadata: None,
            ocr_status: OcrStatus::NotUsed,
            extracted_text: None,
        };

        let result2 = create_test_result("framework1", "pdf", OcrStatus::NotUsed, 100, 1_000_000.0, 10_000_000);

        let refs = vec![&result1_failed, &result2];
        let percentiles = calculate_percentiles(&refs);

        assert!(percentiles.extraction_duration.is_none());
        assert_eq!(percentiles.success_rate_percent, 50.0);
    }
}
