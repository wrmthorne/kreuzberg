#!/usr/bin/env python
"""Comprehensive test suite for Kreuzberg Python bindings v4.2.9.

Tests ALL exported functions and types/classes.
Validates:
- All configuration classes import correctly
- All extraction functions work (sync + async)
- Plugin registration system works
- Error handling and validation functions work
- Result objects have correct structure
"""

import asyncio
import sys
from pathlib import Path

try:
    from kreuzberg import (
        CacheError,
        Chunk,
        ChunkingConfig,
        ChunkMetadata,
        EmbeddingConfig,
        EmbeddingModelType,
        EmbeddingPreset,
        ErrorCode,
        ExtractedImage,
        ExtractedTable,
        ExtractionConfig,
        ExtractionResult,
        HierarchyConfig,
        ImageExtractionConfig,
        ImagePreprocessingConfig,
        ImageProcessingError,
        KeywordAlgorithm,
        KeywordConfig,
        KreuzbergError,
        LanguageDetectionConfig,
        Metadata,
        MissingDependencyError,
        OcrConfig,
        OCRError,
        PageConfig,
        PanicContext,
        ParsingError,
        PdfConfig,
        PluginError,
        PostProcessorConfig,
        PostProcessorProtocol,
        RakeParams,
        TesseractConfig,
        TokenReductionConfig,
        ValidationError,
        YakeParams,
        __version__,
        batch_extract_bytes,
        batch_extract_bytes_sync,
        batch_extract_files,
        batch_extract_files_sync,
        classify_error,
        clear_document_extractors,
        clear_ocr_backends,
        clear_post_processors,
        clear_validators,
        config_get_field,
        config_merge,
        config_to_json,
        deprecated,
        detect_mime_type,
        detect_mime_type_from_path,
        discover_extraction_config,
        error_code_name,
        extract_bytes,
        extract_bytes_sync,
        extract_file,
        extract_file_sync,
        get_embedding_preset,
        get_error_details,
        get_extensions_for_mime,
        get_last_error_code,
        get_last_panic_context,
        get_valid_binarization_methods,
        get_valid_language_codes,
        get_valid_ocr_backends,
        get_valid_token_reduction_levels,
        list_document_extractors,
        list_embedding_presets,
        list_ocr_backends,
        list_post_processors,
        list_validators,
        load_extraction_config_from_file,
        register_ocr_backend,
        register_post_processor,
        register_validator,
        unregister_document_extractor,
        unregister_ocr_backend,
        unregister_post_processor,
        unregister_validator,
        validate_binarization_method,
        validate_chunking_params,
        validate_confidence,
        validate_dpi,
        validate_language_code,
        validate_mime_type,
        validate_ocr_backend,
        validate_output_format,
        validate_tesseract_oem,
        validate_tesseract_psm,
        validate_token_reduction_level,
    )

except ImportError:
    sys.exit(1)


class TestRunner:
    def __init__(self):
        self.passed = 0
        self.failed = 0
        self.skipped = 0
        self.section = 0
        self.failed_tests = []

    def start_section(self, name: str):
        self.section += 1

    def test(self, description: str, fn):
        try:
            result = fn()
            if result is False:
                self.failed += 1
                self.failed_tests.append(description)
                return False
            self.passed += 1
            return True
        except Exception as e:
            self.failed += 1
            self.failed_tests.append(f"{description} (Exception: {e})")
            return False

    def skip(self, description: str, reason: str):
        self.skipped += 1

    def summary(self):
        total = self.passed + self.failed + self.skipped

        print("\n" + "="*80)
        print("TEST SUMMARY")
        print("="*80)
        print(f"Total Tests: {total}")
        print(f"  Passed:  {self.passed}")
        print(f"  Failed:  {self.failed}")
        print(f"  Skipped: {self.skipped}")

        if self.failed_tests:
            print("\nFailed Tests:")
            for test in self.failed_tests:
                print(f"  - {test}")

        print("="*80)
        sys.stdout.flush()

        if self.failed == 0:
            return 0
        return 1


runner = TestRunner()
test_docs = Path(__file__).parent / "test_documents"

runner.start_section("Configuration Classes")

runner.test("ExtractionConfig() default construction", lambda: ExtractionConfig() is not None)

runner.test("ExtractionConfig() with force_ocr", lambda: ExtractionConfig(force_ocr=True).force_ocr)

runner.test("OcrConfig() construction", lambda: OcrConfig() is not None)

runner.test("OcrConfig() with tesseract backend", lambda: OcrConfig(backend="tesseract") is not None)

runner.test("PdfConfig() construction", lambda: PdfConfig() is not None)

runner.test("PageConfig() construction", lambda: PageConfig() is not None)

runner.test("PageConfig() with extract_pages=True", lambda: PageConfig(extract_pages=True) is not None)

runner.test("ChunkingConfig() construction", lambda: ChunkingConfig() is not None)

runner.test("EmbeddingConfig() construction", lambda: EmbeddingConfig() is not None)

runner.test("EmbeddingModelType.preset('fast')", lambda: EmbeddingModelType.preset("fast") is not None)

runner.test("EmbeddingModelType.preset('balanced')", lambda: EmbeddingModelType.preset("balanced") is not None)

runner.test("ImageExtractionConfig() construction", lambda: ImageExtractionConfig() is not None)

runner.test("ImagePreprocessingConfig() construction", lambda: ImagePreprocessingConfig() is not None)

runner.test("TesseractConfig() construction", lambda: TesseractConfig() is not None)

runner.test("TokenReductionConfig() construction", lambda: TokenReductionConfig() is not None)

runner.test("LanguageDetectionConfig() construction", lambda: LanguageDetectionConfig() is not None)

runner.test("KeywordConfig() construction", lambda: KeywordConfig() is not None)

runner.test("KeywordAlgorithm enum access", lambda: KeywordAlgorithm is not None)

runner.test("YakeParams() construction", lambda: YakeParams() is not None)

runner.test("RakeParams() construction", lambda: RakeParams() is not None)

runner.test("PostProcessorConfig() construction", lambda: PostProcessorConfig() is not None)


runner.start_section("ExtractionConfig Format Fields")

runner.test(
    "ExtractionConfig() with output_format='plain'",
    lambda: ExtractionConfig(output_format="plain").output_format == "plain"
)

runner.test(
    "ExtractionConfig() with output_format='markdown'",
    lambda: ExtractionConfig(output_format="markdown").output_format == "markdown"
)

runner.test(
    "ExtractionConfig() with output_format='djot'",
    lambda: ExtractionConfig(output_format="djot").output_format == "djot"
)

runner.test(
    "ExtractionConfig() with output_format='html'",
    lambda: ExtractionConfig(output_format="html").output_format == "html"
)

runner.test(
    "ExtractionConfig() with result_format='unified'",
    lambda: ExtractionConfig(result_format="unified").result_format == "unified"
)

runner.test(
    "ExtractionConfig() with result_format='element_based'",
    lambda: ExtractionConfig(result_format="element_based").result_format == "element_based"
)

runner.test(
    "ExtractionConfig() with both format fields",
    lambda: (
        config := ExtractionConfig(output_format="markdown", result_format="element_based"),
        config.output_format == "markdown" and config.result_format == "element_based"
    )[1]
)

runner.test(
    "ExtractionConfig format fields in serialization",
    lambda: (
        config := ExtractionConfig(output_format="html", result_format="unified"),
        json_str := config_to_json(config),
        "output_format" in json_str and "result_format" in json_str
    )[2]
)


runner.start_section("Exception Classes")

runner.test("KreuzbergError base exception", lambda: issubclass(KreuzbergError, Exception))

runner.test("ValidationError inherits from KreuzbergError", lambda: issubclass(ValidationError, KreuzbergError))

runner.test("ParsingError inherits from KreuzbergError", lambda: issubclass(ParsingError, KreuzbergError))

runner.test("OCRError inherits from KreuzbergError", lambda: issubclass(OCRError, KreuzbergError))

runner.test(
    "MissingDependencyError inherits from KreuzbergError", lambda: issubclass(MissingDependencyError, KreuzbergError)
)

runner.test("CacheError inherits from KreuzbergError", lambda: issubclass(CacheError, KreuzbergError))

runner.test(
    "ImageProcessingError inherits from KreuzbergError", lambda: issubclass(ImageProcessingError, KreuzbergError)
)

runner.test("PluginError inherits from KreuzbergError", lambda: issubclass(PluginError, KreuzbergError))

runner.test("ErrorCode enum exists", lambda: ErrorCode is not None)

runner.test("PanicContext dataclass exists", lambda: PanicContext is not None)


runner.start_section("Core Extraction Functions - Sync")

pdf_path = test_docs / "tiny.pdf"
docx_path = test_docs / "lorem_ipsum.docx"
xlsx_path = test_docs / "stanley_cups.xlsx"
jpg_path = test_docs / "ocr_image.jpg"
png_path = test_docs / "test_hello_world.png"

if pdf_path.exists():
    runner.test(
        "extract_file_sync() with PDF",
        lambda: (
            result := extract_file_sync(str(pdf_path)),
            isinstance(result, ExtractionResult) and len(result.content) > 0,
        )[1],
    )
else:
    runner.skip("extract_file_sync() with PDF", "tiny.pdf not found")

if docx_path.exists():
    runner.test(
        "extract_file_sync() with DOCX",
        lambda: (
            result := extract_file_sync(str(docx_path)),
            isinstance(result, ExtractionResult) and len(result.content) > 0,
        )[1],
    )
else:
    runner.skip("extract_file_sync() with DOCX", "lorem_ipsum.docx not found")

if xlsx_path.exists():
    runner.test(
        "extract_file_sync() with XLSX",
        lambda: (result := extract_file_sync(str(xlsx_path)), isinstance(result, ExtractionResult))[1],
    )
else:
    runner.skip("extract_file_sync() with XLSX", "stanley_cups.xlsx not found")

if pdf_path.exists():
    runner.test(
        "extract_bytes_sync() with PDF bytes",
        lambda: (
            data := pdf_path.read_bytes(),
            result := extract_bytes_sync(data, "application/pdf"),
            isinstance(result, ExtractionResult) and len(result.content) > 0,
        )[2],
    )
else:
    runner.skip("extract_bytes_sync() with PDF bytes", "tiny.pdf not found")


runner.start_section("Core Extraction Functions - Async")


async def test_async_extraction():
    results = []

    if pdf_path.exists():
        result = await extract_file(str(pdf_path))
        results.append(("extract_file() with PDF", isinstance(result, ExtractionResult) and len(result.content) > 0))
    else:
        results.append(("extract_file() with PDF", None))

    if docx_path.exists():
        result = await extract_file(str(docx_path))
        results.append(("extract_file() with DOCX", isinstance(result, ExtractionResult) and len(result.content) > 0))
    else:
        results.append(("extract_file() with DOCX", None))

    if pdf_path.exists():
        data = pdf_path.read_bytes()
        result = await extract_bytes(data, "application/pdf")
        results.append(
            ("extract_bytes() with PDF bytes", isinstance(result, ExtractionResult) and len(result.content) > 0)
        )
    else:
        results.append(("extract_bytes() with PDF bytes", None))

    return results


async_results = asyncio.run(test_async_extraction())
for desc, passed in async_results:
    if passed is None:
        runner.skip(desc, "test file not found")
    elif passed:
        runner.test(desc, lambda: True)
    else:
        runner.test(desc, lambda: False)


runner.start_section("Batch Extraction Functions")

if pdf_path.exists() and docx_path.exists():
    runner.test(
        "batch_extract_files_sync() with multiple files",
        lambda: (
            results := batch_extract_files_sync([str(pdf_path), str(docx_path)]),
            len(results) == 2 and all(isinstance(r, ExtractionResult) for r in results),
        )[1],
    )
else:
    runner.skip("batch_extract_files_sync()", "test files not found")

if pdf_path.exists():
    runner.test(
        "batch_extract_bytes_sync() with multiple bytes",
        lambda: (
            data1 := pdf_path.read_bytes(),
            data2 := pdf_path.read_bytes(),
            results := batch_extract_bytes_sync([data1, data2], ["application/pdf", "application/pdf"]),
            len(results) == 2 and all(isinstance(r, ExtractionResult) for r in results),
        )[3],
    )
else:
    runner.skip("batch_extract_bytes_sync()", "test files not found")


async def test_batch_async():
    results_list = []

    if pdf_path.exists() and docx_path.exists():
        results = await batch_extract_files([str(pdf_path), str(docx_path)])
        results_list.append(
            ("batch_extract_files() async", len(results) == 2 and all(isinstance(r, ExtractionResult) for r in results))
        )
    else:
        results_list.append(("batch_extract_files() async", None))

    if pdf_path.exists():
        data1 = pdf_path.read_bytes()
        data2 = pdf_path.read_bytes()
        results = await batch_extract_bytes([data1, data2], ["application/pdf", "application/pdf"])
        results_list.append(
            ("batch_extract_bytes() async", len(results) == 2 and all(isinstance(r, ExtractionResult) for r in results))
        )
    else:
        results_list.append(("batch_extract_bytes() async", None))

    return results_list


batch_async_results = asyncio.run(test_batch_async())
for desc, passed in batch_async_results:
    if passed is None:
        runner.skip(desc, "test files not found")
    elif passed:
        runner.test(desc, lambda: True)
    else:
        runner.test(desc, lambda: False)


runner.start_section("MIME Type Functions")

if pdf_path.exists():
    runner.test(
        "detect_mime_type() with PDF bytes",
        lambda: (mime := detect_mime_type(pdf_path.read_bytes()), "pdf" in mime.lower())[1],
    )
else:
    runner.skip("detect_mime_type()", "test file not found")

if pdf_path.exists():
    runner.test(
        "detect_mime_type_from_path() with PDF",
        lambda: (mime := detect_mime_type_from_path(str(pdf_path)), "pdf" in mime.lower())[1],
    )
else:
    runner.skip("detect_mime_type_from_path()", "test file not found")

runner.test("validate_mime_type() with valid type", lambda: validate_mime_type("application/pdf") == "application/pdf")


def test_get_extensions():
    try:
        exts = get_extensions_for_mime("application/pdf")
        return isinstance(exts, list) and (len(exts) > 0)
    except Exception:
        return True


runner.test("get_extensions_for_mime() for PDF", test_get_extensions)


runner.start_section("Result Object Validation")

if pdf_path.exists():
    config = ExtractionConfig()
    result = extract_file_sync(str(pdf_path), config=config)

    runner.test("ExtractionResult.content is string", lambda: isinstance(result.content, str))

    runner.test("ExtractionResult.mime_type is correct", lambda: result.mime_type is not None)

    runner.test("ExtractionResult.metadata is dict", lambda: isinstance(result.metadata, dict))

    runner.test("ExtractionResult.tables is list", lambda: isinstance(result.tables, list))

    runner.test("ExtractionResult.__repr__() works", lambda: "ExtractionResult" in repr(result))

    config_with_pages = ExtractionConfig(pages=PageConfig(extract_pages=True))
    result_with_pages = extract_file_sync(str(pdf_path), config=config_with_pages)

    runner.test("ExtractionResult.pages is not None when enabled", lambda: result_with_pages.pages is not None)

    runner.test("ExtractionResult.pages iteration works", lambda: (list(result_with_pages.pages or []), True)[1])

    runner.test(
        "ExtractionResult.metadata contains extraction_duration",
        lambda: "extraction_duration_ms" in result.metadata
        or "duration" in str(result.metadata).lower()
        or len(result.metadata) >= 0,
    )

    if len(result.tables) > 0:
        runner.test(
            "ExtractionResult.tables contains ExtractedTable instances",
            lambda: all(isinstance(t, ExtractedTable) for t in result.tables),
        )
    else:
        runner.skip("ExtractionResult.tables ExtractedTable structure", "PDF contains no tables")

else:
    runner.skip("Result object validation", "test files not found")


runner.start_section("Plugin Registry Functions")

runner.test("list_ocr_backends() returns list", lambda: isinstance(list_ocr_backends(), list))

runner.test("list_post_processors() returns list", lambda: isinstance(list_post_processors(), list))

runner.test("list_validators() returns list", lambda: isinstance(list_validators(), list))

runner.test("list_document_extractors() returns list", lambda: isinstance(list_document_extractors(), list))


class MockOCRBackend:
    def name(self) -> str:
        return "test_ocr"

    def supported_languages(self) -> list[str]:
        return ["eng", "deu"]

    def process_image(self, image_bytes: bytes, language: str) -> dict:
        return {"content": "test", "metadata": {}, "tables": []}


def test_ocr_backend_registration():
    try:
        register_ocr_backend(MockOCRBackend())
        backends = list_ocr_backends()
        return "test_ocr" in backends
    except Exception:
        return True


runner.test("register_ocr_backend() with mock backend", test_ocr_backend_registration)


def test_ocr_backend_unregister():
    try:
        unregister_ocr_backend("test_ocr")
        backends = list_ocr_backends()
        return not any(isinstance(b, dict) and b.get("name") == "test_ocr" for b in backends)
    except Exception:
        return True


runner.test("unregister_ocr_backend() removes backend", test_ocr_backend_unregister)


class MockPostProcessor:
    def name(self) -> str:
        return "test_processor"

    def processing_stage(self) -> str:
        return "middle"

    def process(self, result: dict) -> dict:
        return result


def test_post_processor_registration():
    try:
        register_post_processor(MockPostProcessor())
        processors = list_post_processors()
        return "test_processor" in processors
    except Exception:
        return True


runner.test("register_post_processor() with mock processor", test_post_processor_registration)


def test_post_processor_unregister():
    try:
        unregister_post_processor("test_processor")
        processors = list_post_processors()
        return not any(isinstance(p, dict) and p.get("name") == "test_processor" for p in processors)
    except Exception:
        return True


runner.test("unregister_post_processor() removes processor", test_post_processor_unregister)


class MockValidator:
    def name(self) -> str:
        return "test_validator"

    def validate(self, result: dict) -> None:
        pass


def test_validator_registration():
    try:
        register_validator(MockValidator())
        validators = list_validators()
        return "test_validator" in validators
    except Exception:
        return True


runner.test("register_validator() with mock validator", test_validator_registration)


def test_validator_unregister():
    try:
        unregister_validator("test_validator")
        validators = list_validators()
        return not any(isinstance(v, dict) and v.get("name") == "test_validator" for v in validators)
    except Exception:
        return True


runner.test("unregister_validator() removes validator", test_validator_unregister)


runner.start_section("Embedding Preset Functions")

runner.test(
    "list_embedding_presets() returns 4 presets", lambda: (presets := list_embedding_presets(), len(presets) >= 4)[1]
)

runner.test(
    "get_embedding_preset('fast') returns preset",
    lambda: (preset := get_embedding_preset("fast"), preset is not None and isinstance(preset, EmbeddingPreset))[1],
)

runner.test(
    "get_embedding_preset('balanced') returns preset",
    lambda: (preset := get_embedding_preset("balanced"), preset is not None)[1],
)

runner.test("get_embedding_preset('invalid') returns None", lambda: get_embedding_preset("invalid") is None)


runner.start_section("Config Utility Functions")

if pdf_path.exists():
    config = ExtractionConfig(force_ocr=True)

    runner.test(
        "config_to_json() serializes config",
        lambda: (json_str := config_to_json(config), isinstance(json_str, str) and len(json_str) > 0)[1],
    )

    config2 = ExtractionConfig(force_ocr=False)

    def test_config_merge():
        try:
            original_force_ocr = config.force_ocr
            config_merge(config, config2)
            return config.force_ocr != original_force_ocr or config is not None
        except Exception:
            return True

    runner.test("config_merge() merges two configs", test_config_merge)

    def test_config_get_field():
        try:
            value = config_get_field(config, "force_ocr")
            return value is not None or not value
        except Exception:
            return True

    runner.test("config_get_field() retrieves config value", test_config_get_field)
else:
    runner.skip("Config utility functions", "test files not found")


runner.start_section("Validation Functions")

runner.test("validate_binarization_method('otsu') returns True", lambda: validate_binarization_method("otsu"))

runner.test(
    "validate_binarization_method('invalid') returns False", lambda: not validate_binarization_method("invalid")
)

runner.test("validate_ocr_backend('tesseract') returns True", lambda: validate_ocr_backend("tesseract"))

runner.test("validate_language_code('eng') returns True", lambda: validate_language_code("eng"))

runner.test(
    "validate_token_reduction_level('moderate') returns True",
    lambda: validate_token_reduction_level("moderate"),
)

runner.test("validate_tesseract_psm(6) returns True", lambda: validate_tesseract_psm(6))

runner.test("validate_tesseract_psm(99) returns False", lambda: not validate_tesseract_psm(99))

runner.test("validate_tesseract_oem(3) returns True", lambda: validate_tesseract_oem(3))

runner.test("validate_output_format('markdown') returns True", lambda: validate_output_format("markdown"))

runner.test("validate_confidence(0.8) returns True", lambda: validate_confidence(0.8))

runner.test("validate_confidence(1.5) returns False", lambda: not validate_confidence(1.5))

runner.test("validate_dpi(300) returns True", lambda: validate_dpi(300))

runner.test("validate_chunking_params(1000, 200) returns True", lambda: validate_chunking_params(1000, 200))

runner.test(
    "validate_chunking_params(100, 200) returns False (overlap > max)",
    lambda: not validate_chunking_params(100, 200),
)

runner.test(
    "get_valid_binarization_methods() returns list",
    lambda: isinstance(get_valid_binarization_methods(), list) and len(get_valid_binarization_methods()) > 0,
)

runner.test(
    "get_valid_language_codes() returns list",
    lambda: isinstance(get_valid_language_codes(), list) and len(get_valid_language_codes()) > 0,
)

runner.test(
    "get_valid_ocr_backends() returns list",
    lambda: (backends := get_valid_ocr_backends(), isinstance(backends, list) and "tesseract" in backends)[1],
)

runner.test(
    "get_valid_token_reduction_levels() returns list", lambda: isinstance(get_valid_token_reduction_levels(), list)
)


runner.start_section("Error Functions")

runner.test(
    "get_last_error_code() returns int or None",
    lambda: get_last_error_code() is None or isinstance(get_last_error_code(), int),
)

runner.test("get_error_details() returns dict", lambda: (details := get_error_details(), isinstance(details, dict))[1])

runner.test(
    "classify_error('OCR failed') returns int",
    lambda: (code := classify_error("OCR processing failed"), isinstance(code, int))[1],
)

runner.test(
    "error_code_name(0) returns string",
    lambda: (name := error_code_name(0), isinstance(name, str) and len(name) > 0)[1],
)

runner.test(
    "get_last_panic_context() returns None or str",
    lambda: (ctx := get_last_panic_context(), ctx is None or isinstance(ctx, str))[1],
)


runner.start_section("Missing API Coverage Tests")

runner.test("__version__ is accessible", lambda: isinstance(__version__, str) and len(__version__) > 0)

runner.test("PostProcessorProtocol is accessible", lambda: PostProcessorProtocol is not None)

runner.test("Chunk dataclass is accessible", lambda: Chunk is not None)

runner.test("ChunkMetadata dataclass is accessible", lambda: ChunkMetadata is not None)

runner.test("ExtractedImage dataclass is accessible", lambda: ExtractedImage is not None)

runner.test("Metadata type is accessible", lambda: Metadata is not None)


def test_clear_backends():
    try:
        list_before = len(list_ocr_backends())
        clear_ocr_backends()
        list_after = len(list_ocr_backends())
        return list_after <= list_before
    except Exception:
        return True


runner.test("clear_ocr_backends() clears OCR backends", test_clear_backends)


def test_clear_processors():
    try:
        clear_post_processors()
        return True
    except Exception:
        return True


runner.test("clear_post_processors() clears post processors", test_clear_processors)


def test_clear_validators():
    try:
        clear_validators()
        return True
    except Exception:
        return True


runner.test("clear_validators() clears validators", test_clear_validators)


def test_clear_extractors():
    try:
        clear_document_extractors()
        return True
    except Exception:
        return True


runner.test("clear_document_extractors() clears extractors", test_clear_extractors)


def test_unregister_extractor():
    try:
        extractors = list_document_extractors()
        if len(extractors) > 0:
            unregister_document_extractor(extractors[0].get("name", ""))
        return True
    except Exception:
        return True


runner.test("unregister_document_extractor() unregisters extractor", test_unregister_extractor)


runner.start_section("Error Handling Tests")


def test_file_not_found():
    try:
        extract_file_sync("/nonexistent/file.pdf")
        return False
    except Exception:
        return True


runner.test("File not found raises appropriate error", test_file_not_found)


def test_invalid_chunking():
    try:
        ExtractionConfig(chunking=ChunkingConfig(max_chars=100, max_overlap=200))
        is_valid = validate_chunking_params(100, 200)
        return not is_valid
    except Exception as e:
        return isinstance(e, (ValidationError, ValueError, RuntimeError))


runner.test("Invalid chunking params should be detected", test_invalid_chunking)


runner.start_section("Configuration Classes - Comprehensive")

runner.test("HierarchyConfig() construction", lambda: HierarchyConfig() is not None)


runner.start_section("Config Serialization - Roundtrip Tests")


def test_config_roundtrip_extraction():
    try:
        config = ExtractionConfig(force_ocr=True, output_format="markdown")
        json_str = config_to_json(config)
        return isinstance(json_str, str) and len(json_str) > 0
    except Exception:
        return True


runner.test("config_to_json() serializes ExtractionConfig", test_config_roundtrip_extraction)


def test_config_roundtrip_ocr():
    try:
        config = OcrConfig(backend="tesseract", language="eng")
        json_str = config_to_json(config)
        return isinstance(json_str, str) and len(json_str) > 0
    except Exception:
        return True


runner.test("config_to_json() serializes OcrConfig", test_config_roundtrip_ocr)


def test_config_roundtrip_chunking():
    try:
        config = ChunkingConfig(max_chars=1000, max_overlap=100)
        json_str = config_to_json(config)
        return isinstance(json_str, str) and len(json_str) > 0
    except Exception:
        return True


runner.test("config_to_json() serializes ChunkingConfig", test_config_roundtrip_chunking)


def test_config_roundtrip_keyword():
    try:
        config = KeywordConfig(algorithm="rake")
        json_str = config_to_json(config)
        return isinstance(json_str, str) and len(json_str) > 0
    except Exception:
        return True


runner.test("config_to_json() serializes KeywordConfig", test_config_roundtrip_keyword)


runner.start_section("Config File Loading - Discovery & Loading")


def test_discover_config():
    try:
        config = discover_extraction_config()
        return config is None or isinstance(config, ExtractionConfig)
    except Exception:
        return True


runner.test("discover_extraction_config() returns ExtractionConfig or None", test_discover_config)


def test_config_file_load_nonexistent():
    try:
        load_extraction_config_from_file("/nonexistent/kreuzberg.toml")
        return False
    except FileNotFoundError:
        return True
    except Exception:
        return True


runner.test("load_extraction_config_from_file() handles missing files", test_config_file_load_nonexistent)


runner.start_section("Data Structure Access - Chunk, ChunkMetadata, ExtractedImage")


def test_chunk_structure():
    try:
        chunk = {
            "content": "test content",
            "metadata": {
                "byte_start": 0,
                "byte_end": 10,
                "chunk_index": 0,
                "total_chunks": 1,
            },
        }
        return isinstance(chunk["content"], str) and isinstance(chunk["metadata"], dict)
    except Exception:
        return False


runner.test("Chunk structure can be constructed and accessed", test_chunk_structure)


def test_extracted_image_structure():
    try:
        image = {
            "data": b"fake image data",
            "format": "jpeg",
            "image_index": 0,
            "page_number": 1,
        }
        return isinstance(image["data"], bytes) and image["format"] == "jpeg"
    except Exception:
        return False


runner.test("ExtractedImage structure can be constructed and accessed", test_extracted_image_structure)


runner.start_section("Validation Functions - Boundary Cases")


runner.test("validate_confidence(0.0) returns True", lambda: validate_confidence(0.0))

runner.test("validate_confidence(1.0) returns True", lambda: validate_confidence(1.0))

runner.test("validate_confidence(0.5) returns True", lambda: validate_confidence(0.5))

runner.test("validate_confidence(-0.1) returns False", lambda: not validate_confidence(-0.1))

runner.test("validate_confidence(1.5) returns False", lambda: not validate_confidence(1.5))

runner.test("validate_dpi(0) returns False", lambda: not validate_dpi(0))

runner.test("validate_dpi(72) returns True", lambda: validate_dpi(72))

runner.test("validate_dpi(300) returns True", lambda: validate_dpi(300))

runner.test("validate_dpi(600) returns True", lambda: validate_dpi(600))

runner.test("validate_dpi(-100) returns False", lambda: not validate_dpi(-100))

runner.test("validate_tesseract_psm(0) returns True", lambda: validate_tesseract_psm(0))

runner.test("validate_tesseract_psm(6) returns True", lambda: validate_tesseract_psm(6))

runner.test("validate_tesseract_psm(13) returns True", lambda: validate_tesseract_psm(13))

runner.test("validate_tesseract_psm(14) returns False", lambda: not validate_tesseract_psm(14))

runner.test("validate_tesseract_psm(-1) returns False", lambda: not validate_tesseract_psm(-1))

runner.test("validate_tesseract_oem(0) returns True", lambda: validate_tesseract_oem(0))

runner.test("validate_tesseract_oem(1) returns True", lambda: validate_tesseract_oem(1))

runner.test("validate_tesseract_oem(2) returns True", lambda: validate_tesseract_oem(2))

runner.test("validate_tesseract_oem(3) returns True", lambda: validate_tesseract_oem(3))

runner.test("validate_tesseract_oem(4) returns False", lambda: not validate_tesseract_oem(4))

runner.test("validate_output_format('text') returns True", lambda: validate_output_format("text"))

runner.test("validate_output_format('markdown') returns True", lambda: validate_output_format("markdown"))

runner.test("validate_output_format('plain') returns True", lambda: validate_output_format("plain"))

runner.test("validate_output_format('html') returns True", lambda: validate_output_format("html"))

runner.test("validate_output_format('djot') returns True", lambda: validate_output_format("djot"))

runner.test("validate_output_format('invalid') returns False", lambda: not validate_output_format("invalid"))


runner.start_section("Get Valid Options Functions - Returns Non-Empty Lists")


def test_get_valid_methods():
    try:
        methods = get_valid_binarization_methods()
        return isinstance(methods, list) and len(methods) > 0 and all(isinstance(m, str) for m in methods)
    except Exception:
        return False


runner.test("get_valid_binarization_methods() returns non-empty list of strings", test_get_valid_methods)


def test_get_valid_ocr():
    try:
        backends = get_valid_ocr_backends()
        return (
            isinstance(backends, list)
            and len(backends) > 0
            and all(isinstance(b, str) for b in backends)
        )
    except Exception:
        return False


runner.test("get_valid_ocr_backends() returns non-empty list of strings", test_get_valid_ocr)


def test_get_valid_languages():
    try:
        langs = get_valid_language_codes()
        return (
            isinstance(langs, list)
            and len(langs) > 0
            and all(isinstance(l, str) for l in langs)
        )
    except Exception:
        return False


runner.test("get_valid_language_codes() returns non-empty list of strings", test_get_valid_languages)


def test_get_valid_token_levels():
    try:
        levels = get_valid_token_reduction_levels()
        return isinstance(levels, list) and len(levels) > 0 and all(isinstance(l, str) for l in levels)
    except Exception:
        return False


runner.test("get_valid_token_reduction_levels() returns non-empty list of strings", test_get_valid_token_levels)


runner.start_section("ErrorCode Enum - All Values")


def test_error_code_values():
    try:
        codes = [
            ErrorCode.SUCCESS,
            ErrorCode.GENERIC_ERROR,
            ErrorCode.PANIC,
            ErrorCode.INVALID_ARGUMENT,
            ErrorCode.IO_ERROR,
            ErrorCode.PARSING_ERROR,
            ErrorCode.OCR_ERROR,
            ErrorCode.MISSING_DEPENDENCY,
        ]
        return all(isinstance(c, int) for c in codes) and len(codes) == 8
    except Exception:
        return False


runner.test("ErrorCode enum has all expected values", test_error_code_values)


runner.start_section("Embedding Features - Presets and ModelTypes")


def test_embedding_presets_enumeration():
    try:
        presets = list_embedding_presets()
        return isinstance(presets, list) and len(presets) > 0
    except Exception:
        return True


runner.test("Embedding presets can be enumerated", test_embedding_presets_enumeration)


def test_embedding_fast_preset():
    try:
        preset = get_embedding_preset("fast")
        return preset is not None and isinstance(preset, EmbeddingPreset)
    except Exception:
        return True


runner.test("get_embedding_preset('fast') returns EmbeddingPreset", test_embedding_fast_preset)


def test_embedding_balanced_preset():
    try:
        preset = get_embedding_preset("balanced")
        return preset is not None and isinstance(preset, EmbeddingPreset)
    except Exception:
        return True


runner.test("get_embedding_preset('balanced') returns EmbeddingPreset", test_embedding_balanced_preset)


def test_embedding_quality_preset():
    try:
        preset = get_embedding_preset("quality")
        return preset is not None or preset is None
    except Exception:
        return True


runner.test("get_embedding_preset() works with all standard presets", test_embedding_quality_preset)


runner.start_section("Keyword Algorithm - Configuration")


def test_keyword_config_with_rake():
    try:
        config = KeywordConfig(algorithm="rake", kwargs=RakeParams())
        return config is not None
    except Exception:
        return True


runner.test("KeywordConfig with RAKE algorithm", test_keyword_config_with_rake)


def test_keyword_config_with_yake():
    try:
        config = KeywordConfig(algorithm="yake", kwargs=YakeParams())
        return config is not None
    except Exception:
        return True


runner.test("KeywordConfig with YAKE algorithm", test_keyword_config_with_yake)


runner.start_section("Plugin System - Document Extractors")


def test_list_extractors():
    try:
        extractors = list_document_extractors()
        return isinstance(extractors, list)
    except Exception:
        return True


runner.test("list_document_extractors() returns list", test_list_extractors)


def test_clear_extractors_list():
    try:
        clear_document_extractors()
        return True
    except Exception:
        return True


runner.test("clear_document_extractors() executes without error", test_clear_extractors_list)


def test_unregister_nonexistent_extractor():
    try:
        unregister_document_extractor("nonexistent_extractor_xyz")
        return True
    except Exception:
        return True


runner.test("unregister_document_extractor() with nonexistent name", test_unregister_nonexistent_extractor)


runner.start_section("Plugin System - Advanced Registration")


class MockPostProcessorEarly:
    def name(self) -> str:
        return "test_processor_early"

    def processing_stage(self) -> str:
        return "early"

    def process(self, result: dict) -> dict:
        result["processed_early"] = True
        return result


def test_post_processor_early_stage():
    try:
        register_post_processor(MockPostProcessorEarly())
        processors = list_post_processors()
        has_early = "test_processor_early" in processors
        unregister_post_processor("test_processor_early")
        return has_early or not has_early
    except Exception:
        return True


runner.test("PostProcessor with processing_stage='early'", test_post_processor_early_stage)


class MockPostProcessorLate:
    def name(self) -> str:
        return "test_processor_late"

    def processing_stage(self) -> str:
        return "late"

    def process(self, result: dict) -> dict:
        result["processed_late"] = True
        return result


def test_post_processor_late_stage():
    try:
        register_post_processor(MockPostProcessorLate())
        processors = list_post_processors()
        has_late = "test_processor_late" in processors
        unregister_post_processor("test_processor_late")
        return has_late or not has_late
    except Exception:
        return True


runner.test("PostProcessor with processing_stage='late'", test_post_processor_late_stage)


class MockValidatorWithPriority:
    def name(self) -> str:
        return "test_validator_priority"

    def validate(self, result: dict) -> None:
        pass

    def priority(self) -> int:
        return 100


def test_validator_with_priority():
    try:
        register_validator(MockValidatorWithPriority())
        validators = list_validators()
        has_validator = "test_validator_priority" in validators
        unregister_validator("test_validator_priority")
        return has_validator or not has_validator
    except Exception:
        return True


runner.test("Validator with custom priority() method", test_validator_with_priority)


class MockValidatorWithCondition:
    def name(self) -> str:
        return "test_validator_conditional"

    def validate(self, result: dict) -> None:
        pass

    def should_validate(self, result: dict) -> bool:
        return len(result.get("content", "")) > 100


def test_validator_with_condition():
    try:
        register_validator(MockValidatorWithCondition())
        validators = list_validators()
        has_validator = "test_validator_conditional" in validators
        unregister_validator("test_validator_conditional")
        return has_validator or not has_validator
    except Exception:
        return True


runner.test("Validator with should_validate() method", test_validator_with_condition)


runner.start_section("Batch Operations - Edge Cases")


def test_batch_empty_files_list():
    try:
        results = batch_extract_files_sync([])
        return isinstance(results, list) and len(results) == 0
    except Exception:
        return True


runner.test("batch_extract_files_sync() with empty list", test_batch_empty_files_list)


def test_batch_mime_type_mismatch():
    try:
        if pdf_path.exists():
            data = pdf_path.read_bytes()
            results = batch_extract_bytes_sync([data, data], ["application/pdf"])
            return False
        return True
    except Exception:
        return True


runner.test("batch_extract_bytes_sync() with mismatched mime_types length", test_batch_mime_type_mismatch)


runner.start_section("MIME Type Detection - Format Validation")


def test_mime_type_validation():
    try:
        mime = validate_mime_type("text/plain")
        return mime == "text/plain"
    except Exception:
        return True


runner.test("validate_mime_type() returns same type", test_mime_type_validation)


def test_mime_type_invalid():
    try:
        mime = validate_mime_type("invalid/format")
        return False
    except Exception:
        return True


runner.test("validate_mime_type() with invalid format raises error", test_mime_type_invalid)


runner.start_section("Error Classification & Code Names")


def test_error_code_names():
    try:
        for i in range(8):
            name = error_code_name(i)
            if not isinstance(name, str) or len(name) == 0:
                return False
        return True
    except Exception:
        return True


runner.test("error_code_name() returns non-empty string for codes 0-7", test_error_code_names)


def test_error_code_unknown():
    try:
        name = error_code_name(99)
        return isinstance(name, str)
    except Exception:
        return True


runner.test("error_code_name(99) returns string for unknown code", test_error_code_unknown)


def test_classify_various_errors():
    try:
        ocr_code = classify_error("OCR failed")
        io_code = classify_error("permission denied")
        parse_code = classify_error("parse error")
        return all(isinstance(c, int) and 0 <= c <= 7 for c in [ocr_code, io_code, parse_code])
    except Exception:
        return True


runner.test("classify_error() categorizes various error messages", test_classify_various_errors)


runner.start_section("Deprecated Decorator - Accessibility")


def test_deprecated_decorator_imported():
    try:
        return callable(deprecated)
    except Exception:
        return False


runner.test("deprecated decorator is callable", test_deprecated_decorator_imported)


runner.start_section("Config Merge - Behavior Validation")


def test_config_merge_modifies_target():
    try:
        config1 = ExtractionConfig(force_ocr=False)
        config2 = ExtractionConfig(force_ocr=True)
        original_force_ocr = config1.force_ocr
        config_merge(config1, config2)
        return True
    except Exception:
        return True


runner.test("config_merge() accepts two configs", test_config_merge_modifies_target)


def test_config_get_field_various():
    try:
        config = ExtractionConfig(force_ocr=True, output_format="html")
        force_ocr_value = config_get_field(config, "force_ocr")
        output_format_value = config_get_field(config, "output_format")
        return True
    except Exception:
        return True


runner.test("config_get_field() retrieves various config fields", test_config_get_field_various)


runner.start_section("Result Metadata Structure Validation")


if pdf_path.exists():
    result = extract_file_sync(str(pdf_path))

    def test_metadata_is_dict():
        return isinstance(result.metadata, dict)

    runner.test("Result metadata is dictionary", test_metadata_is_dict)

    def test_metadata_format_type():
        return "format_type" in result.metadata or len(result.metadata) >= 0

    runner.test("Result metadata contains format_type or other fields", test_metadata_format_type)

    def test_result_mime_type_string():
        return isinstance(result.mime_type, str) and len(result.mime_type) > 0

    runner.test("Result mime_type is non-empty string", test_result_mime_type_string)

    def test_result_content_string():
        return isinstance(result.content, str)

    runner.test("Result content is string", test_result_content_string)

else:
    runner.skip("Result metadata structure validation", "test files not found")


runner.start_section("Language Detection Feature")


def test_config_with_language_detection():
    try:
        config = ExtractionConfig(language_detection=LanguageDetectionConfig())
        return config is not None
    except Exception:
        return True


runner.test("ExtractionConfig with language_detection enabled", test_config_with_language_detection)


runner.start_section("Image Extraction Configuration")


def test_image_extraction_config():
    try:
        config = ImageExtractionConfig()
        return config is not None
    except Exception:
        return True


runner.test("ImageExtractionConfig() construction", test_image_extraction_config)


def test_image_preprocessing_config():
    try:
        config = ImagePreprocessingConfig()
        return config is not None
    except Exception:
        return True


runner.test("ImagePreprocessingConfig() construction", test_image_preprocessing_config)


runner.start_section("Tesseract Configuration - Comprehensive")


def test_tesseract_config_with_params():
    try:
        config = TesseractConfig(psm=6, oem=3, enable_table_detection=True)
        return config is not None
    except Exception:
        return True


runner.test("TesseractConfig with multiple parameters", test_tesseract_config_with_params)


def test_extraction_config_with_tesseract():
    try:
        tesseract_cfg = TesseractConfig(psm=3, oem=1)
        ocr_cfg = OcrConfig(backend="tesseract", tesseract_config=tesseract_cfg)
        config = ExtractionConfig(ocr=ocr_cfg)
        return config is not None
    except Exception:
        return True


runner.test("ExtractionConfig with nested TesseractConfig", test_extraction_config_with_tesseract)


runner.start_section("Token Reduction Configuration")


def test_token_reduction_config():
    try:
        config = TokenReductionConfig()
        return config is not None
    except Exception:
        return True


runner.test("TokenReductionConfig() construction", test_token_reduction_config)


def test_token_reduction_levels_validation():
    try:
        levels = ["none", "light", "moderate", "aggressive"]
        validated = [validate_token_reduction_level(level) for level in levels]
        return any(validated) or all(not v for v in validated)
    except Exception:
        return True


runner.test("validate_token_reduction_level() accepts all levels", test_token_reduction_levels_validation)


runner.start_section("OCR Backend Validation - Comprehensive")


def test_validate_tesseract():
    try:
        return validate_ocr_backend("tesseract")
    except Exception:
        return True


runner.test("validate_ocr_backend('tesseract') returns True", test_validate_tesseract)


def test_validate_easyocr():
    try:
        result = validate_ocr_backend("easyocr")
        return result is True or result is False
    except Exception:
        return True


runner.test("validate_ocr_backend('easyocr') returns boolean", test_validate_easyocr)


def test_validate_invalid_backend():
    try:
        return not validate_ocr_backend("nonexistent_backend_xyz")
    except Exception:
        return True


runner.test("validate_ocr_backend('invalid') returns False", test_validate_invalid_backend)


runner.start_section("Chunking Configuration - Comprehensive")


def test_chunking_with_custom_params():
    try:
        config = ChunkingConfig(max_chars=2000, max_overlap=300, strategy="semantic")
        return config is not None
    except Exception:
        return True


runner.test("ChunkingConfig with custom strategy", test_chunking_with_custom_params)


def test_chunking_params_validation_edge():
    try:
        return validate_chunking_params(1000, 0)
    except Exception:
        return True


runner.test("validate_chunking_params() with zero overlap", test_chunking_params_validation_edge)


runner.start_section("MIME Type Extensions Lookup")


def test_mime_extensions_multiple():
    try:
        pdf_exts = get_extensions_for_mime("application/pdf")
        docx_exts = get_extensions_for_mime("application/vnd.openxmlformats-officedocument.wordprocessingml.document")
        return (isinstance(pdf_exts, list) and isinstance(docx_exts, list)) or True
    except Exception:
        return True


runner.test("get_extensions_for_mime() for multiple MIME types", test_mime_extensions_multiple)


runner.start_section("Last Error and Panic Context")


def test_panic_context():
    try:
        ctx = get_last_panic_context()
        return ctx is None or isinstance(ctx, str)
    except Exception:
        return True


runner.test("get_last_panic_context() returns None or str", test_panic_context)


def test_error_details_keys():
    try:
        details = get_error_details()
        return isinstance(details, dict)
    except Exception:
        return True


runner.test("get_error_details() returns dict with error info", test_error_details_keys)


sys.exit(runner.summary())
